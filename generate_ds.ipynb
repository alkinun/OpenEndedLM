{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "\n",
    "def llm_generate(prompt, model=\"qwen2.5:14b\", options={}):\n",
    "    response = ollama.generate(model=model, prompt=prompt, raw=True, options=options)\n",
    "    return response[\"response\"]\n",
    "\n",
    "def llm(messages, model=\"qwen2.5:14b\"):\n",
    "    response = ollama.chat(model=model, messages=messages)\n",
    "    return response[\"message\"][\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_QUESTION_GENERATION = \"\"\"<|im_start|>system\n",
    "You are a helpful assistant. The user ends its message with \"<|im_end|>\" suffix.<|im_end|>\n",
    "<|im_start|>user\n",
    "\"\"\"\n",
    "\n",
    "def generate_prompt(model=\"qwen2.5:14b\"):\n",
    "    return llm_generate(PROMPT_QUESTION_GENERATION, model=model, options={\"stop\": [\"<|im_end|>\", \"<|im_start|>\"], \"temperature\": 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "ds = []\n",
    "\n",
    "for i in tqdm(range(2000)):\n",
    "    prompt = generate_prompt()\n",
    "    responses = []\n",
    "    for j in range(3):\n",
    "        response = llm([{\"role\": \"user\", \"content\": prompt}])\n",
    "        responses.append(response)\n",
    "    ds.append({\"prompt\": prompt, \"responses\": responses})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "len(ds)\n",
    "with open(\"ds.json\", \"w\") as f:\n",
    "    f.write(json.dumps(ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = json.loads(open(\"ds.json\").read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reward import reward\n",
    "rewards = reward(ds[0][\"prompt\"], ds[0][\"responses\"])\n",
    "print(rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "ds_with_rewards = []\n",
    "\n",
    "for example in tqdm(ds):\n",
    "    new_example = {\n",
    "        \"prompt\": example[\"prompt\"],\n",
    "        \"responses\": example[\"responses\"],\n",
    "        \"rewards\": reward(example[\"prompt\"], example[\"responses\"]),\n",
    "    }\n",
    "    ds_with_rewards.append(new_example)\n",
    "\n",
    "ds = ds_with_rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ds[0][\"prompt\"])\n",
    "print(\"##########################################################################\")\n",
    "print(ds[0][\"responses\"][0])\n",
    "print(\"--- reward: \", ds[0][\"rewards\"][0])\n",
    "print(\"--------------------------------------------------------------------------\")\n",
    "print(ds[0][\"responses\"][1])\n",
    "print(\"--- reward: \", ds[0][\"rewards\"][1])\n",
    "print(\"--------------------------------------------------------------------------\")\n",
    "print(ds[0][\"responses\"][2])\n",
    "print(\"--- reward: \", ds[0][\"rewards\"][2])\n",
    "print(\"--------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "preference_ds = []\n",
    "\n",
    "for example in ds:\n",
    "    best = example[\"responses\"][example[\"rewards\"].index(max(example[\"rewards\"]))]\n",
    "\n",
    "    preference_ds.append({\n",
    "            \"prompt\": example[\"prompt\"],\n",
    "            \"response\": best,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "ds = Dataset.from_list(preference_ds)\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.push_to_hub(\"OpenEndedLM/OpenEnded-v0.2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
