{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "==((====))==  Unsloth 2024.10.7: Fast Qwen2 patching. Transformers = 4.45.2.\n",
      "   \\\\   /|    GPU: NVIDIA GeForce RTX 3090. Max memory: 23.668 GB. Platform = Linux.\n",
      "O^O/ \\_/ \\    Pytorch: 2.4.0+cu121. CUDA = 8.6. CUDA Toolkit = 12.1.\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.27.post2. FA2 = True]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:204: SyntaxWarning: invalid escape sequence '\\ '\n",
      "<string>:205: SyntaxWarning: invalid escape sequence '\\_'\n",
      "<string>:206: SyntaxWarning: invalid escape sequence '\\ '\n",
      "<string>:204: SyntaxWarning: invalid escape sequence '\\ '\n",
      "<string>:205: SyntaxWarning: invalid escape sequence '\\_'\n",
      "<string>:206: SyntaxWarning: invalid escape sequence '\\ '\n",
      "Unsloth: We fixed a gradient accumulation bug, but it seems like you don't have the latest transformers version!\n",
      "Please update transformers, TRL and unsloth via:\n",
      "`pip install --upgrade --no-cache-dir --no-deps unsloth transformers git+https://github.com/huggingface/trl.git`\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "\n",
    "max_seq_length = 4096 # Choose any! We auto support RoPE Scaling internally!\n",
    "dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
    "load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.\n",
    "\n",
    "model, tokenizer=FastLanguageModel.from_pretrained(\n",
    "    model_name=\"Qwen/Qwen2.5-1.5B-Instruct\",\n",
    "    max_seq_length=max_seq_length,\n",
    "    dtype=dtype,\n",
    "    load_in_4bit=load_in_4bit,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2024.10.7 patched 28 layers with 0 QKV layers, 28 O layers and 28 MLP layers.\n"
     ]
    }
   ],
   "source": [
    "model=FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r=64, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                    \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
    "    lora_alpha=64,\n",
    "    lora_dropout=0, # Currently only supports dropout=0\n",
    "    bias=\"none\",    # Currently only supports bias=\"none\"\n",
    "    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n",
    "    use_gradient_checkpointing=\"unsloth\", # True or \"unsloth\" for very long context\n",
    "    random_state=3407,\n",
    "    use_rslora=False,  # We support rank stabilized LoRA\n",
    "    loftq_config=None, # And LoftQ\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b5e3b3b3c52483d9f557e9f8184ba61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt_template = \"\"\"<|im_start|>system\n",
    "You are a helpful assistant.<|im_end|>\n",
    "<|im_start|>user\n",
    "{}<|im_end|>\n",
    "<|im_start|>assistant\n",
    "{}<|im_end|>\"\"\"\n",
    "\n",
    "EOS_TOKEN = tokenizer.eos_token # Must add EOS_TOKEN\n",
    "\n",
    "def format_prompt(examples):\n",
    "    prompts   = examples[\"prompt\"]\n",
    "    responses = examples[\"response\"]\n",
    "    texts = []\n",
    "    for prompt, response in zip(prompts, responses):\n",
    "        # Must add EOS_TOKEN, otherwise your generation will go on forever!\n",
    "        text = prompt_template.format(prompt, response)\n",
    "        texts.append(text)\n",
    "    return {\"text\": texts}\n",
    "\n",
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"OpenEndedLM/OpenEnded-v0.2\")[\"train\"]\n",
    "dataset = dataset.map(format_prompt, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system\n",
      "You are a helpful assistant.<|im_end|>\n",
      "<|im_start|>user\n",
      "Can you explain the difference between an abstract class and an interface in Java? What situations would you use one over the other?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "In Java, both abstract classes and interfaces serve to define a blueprint for objects or common behaviors but do so in different ways:\n",
      "\n",
      "### Abstract Class\n",
      "\n",
      "1. **Definition**: An abstract class is a class that cannot be instantiated on its own; it must be inherited by another (concrete) class.\n",
      "2. **Abstract Methods & Concrete Methods**:\n",
      "   - You can have both abstract methods (methods without implementation) and concrete methods (methods with implementations) in an abstract class.\n",
      "3. **Field Access Modifiers**: Fields in abstract classes can have any access modifier, allowing them to be `public`, `private`, or protected`.\n",
      "4. **Use Case**: Use an abstract class when you want to define common fields and behaviors that are shared among multiple subclasses but also provide some default behavior that doesn't need to change across different implementations.\n",
      "5. **Example**:\n",
      "   ```java\n",
      "   public abstract class Animal {\n",
      "       private String name;\n",
      "\n",
      "       public Animal(String name) {\n",
      "           this.name = name;\n",
      "       }\n",
      "\n",
      "       // Abstract method, must be implemented by concrete classes\n",
      "       public abstract void makeSound();\n",
      "\n",
      "       // Concrete method with default behavior\n",
      "       public void eat() {\n",
      "           System.out.println(name + \" is eating.\");\n",
      "       }\n",
      "   }\n",
      "   ```\n",
      "\n",
      "### Interface\n",
      "\n",
      "1. **Definition**: An interface defines a contract for what a class should do without providing any implementation details.\n",
      "2. **Methods and Fields**:\n",
      "   - All methods in an interface are implicitly abstract (except since Java 8, where you can define default and static methods).\n",
      "   - Interfaces cannot declare fields other than `static final` variables which must be initialized at the time of declaration.\n",
      "3. **Field Access Modifiers**: In interfaces, fields have to be public static final by definition.\n",
      "4. **Use Case**: Use an interface when multiple unrelated classes need to implement similar behavior or when you are working with existing code and cannot use inheritance (due to Java's single inheritance limitation).\n",
      "5. **Example**:\n",
      "   ```java\n",
      "   public interface Soundable {\n",
      "       void makeSound();\n",
      "       \n",
      "       // Since Java 8, default methods can be defined in interfaces.\n",
      "       default void printDefault() {\n",
      "           System.out.println(\"This is a default method.\");\n",
      "       }\n",
      "   }\n",
      "\n",
      "   class Dog implements Animal, Soundable { ... }\n",
      "   ```\n",
      "\n",
      "### When to Use Which?\n",
      "\n",
      "- **Abstract Class**: Prefer using an abstract class when you want to provide some common behavior that can be shared among multiple subclasses. Abstract classes are also beneficial if the entity hierarchy has at least one common base state or implementation details that should not vary across different implementations.\n",
      "  \n",
      "- **Interface**: Interfaces are more suitable for defining a set of behaviors (capabilities) that an object might have regardless of its type, especially when these behaviors need to be implemented by multiple unrelated classes. They're also ideal for scenarios involving the extension of functionality in third-party code without modifying it.\n",
      "\n",
      "In summary, choose abstract classes when you want to provide shared state and behavior among subclasses, while choosing interfaces to define capabilities that can be implemented independently across various classes.<|im_end|>\n"
     ]
    }
   ],
   "source": [
    "print(dataset[\"text\"][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c40c2539c6184ede8a549b58d6eec2df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=2):   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from trl import SFTTrainer\n",
    "from transformers import TrainingArguments\n",
    "from unsloth import is_bfloat16_supported\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    train_dataset = dataset,\n",
    "    dataset_text_field = \"text\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    dataset_num_proc = 2,\n",
    "    packing = False, # Can make training 5x faster for short sequences.\n",
    "    args = TrainingArguments(\n",
    "        per_device_train_batch_size = 2,\n",
    "        gradient_accumulation_steps = 4,\n",
    "        warmup_steps = 5,\n",
    "\n",
    "        num_train_epochs = 2,\n",
    "        #max_steps = 60,\n",
    "\n",
    "        learning_rate = 2e-4,\n",
    "        fp16 = not is_bfloat16_supported(),\n",
    "        bf16 = is_bfloat16_supported(),\n",
    "        logging_steps = 1,\n",
    "        optim = \"adamw_8bit\",\n",
    "        weight_decay = 0.01,\n",
    "        lr_scheduler_type = \"linear\",\n",
    "        seed = 3407,\n",
    "        output_dir = \"outputs\",\n",
    "        report_to = \"none\", # Use this for WandB etc\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
      "   \\\\   /|    Num examples = 2,000 | Num Epochs = 2\n",
      "O^O/ \\_/ \\    Batch size per device = 2 | Gradient Accumulation steps = 4\n",
      "\\        /    Total batch size = 8 | Total steps = 500\n",
      " \"-____-\"     Number of trainable parameters = 73,859,072\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** Unsloth: Please use our fixed gradient_accumulation_steps by updating transformers, TRL and Unsloth!\n",
      "`pip install --upgrade --no-cache-dir --no-deps unsloth transformers git+https://github.com/huggingface/trl.git`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb626e76fd574d28be84b3cc1c8ef881",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.3925, 'grad_norm': 0.7581949234008789, 'learning_rate': 4e-05, 'epoch': 0.0}\n",
      "{'loss': 1.3313, 'grad_norm': 0.6711294054985046, 'learning_rate': 8e-05, 'epoch': 0.01}\n",
      "{'loss': 1.3238, 'grad_norm': 0.625776469707489, 'learning_rate': 0.00012, 'epoch': 0.01}\n",
      "{'loss': 1.1564, 'grad_norm': 0.5471979975700378, 'learning_rate': 0.00016, 'epoch': 0.02}\n",
      "{'loss': 1.3209, 'grad_norm': 0.509019136428833, 'learning_rate': 0.0002, 'epoch': 0.02}\n",
      "{'loss': 1.1166, 'grad_norm': 0.5876598954200745, 'learning_rate': 0.0001995959595959596, 'epoch': 0.02}\n",
      "{'loss': 1.1308, 'grad_norm': 0.42803826928138733, 'learning_rate': 0.0001991919191919192, 'epoch': 0.03}\n",
      "{'loss': 0.9379, 'grad_norm': 0.35973235964775085, 'learning_rate': 0.00019878787878787878, 'epoch': 0.03}\n",
      "{'loss': 1.09, 'grad_norm': 0.3838503360748291, 'learning_rate': 0.00019838383838383837, 'epoch': 0.04}\n",
      "{'loss': 0.9814, 'grad_norm': 0.3114466369152069, 'learning_rate': 0.000197979797979798, 'epoch': 0.04}\n",
      "{'loss': 0.7578, 'grad_norm': 0.3007929027080536, 'learning_rate': 0.0001975757575757576, 'epoch': 0.04}\n",
      "{'loss': 1.0861, 'grad_norm': 0.25828513503074646, 'learning_rate': 0.0001971717171717172, 'epoch': 0.05}\n",
      "{'loss': 1.0888, 'grad_norm': 0.3009701073169708, 'learning_rate': 0.00019676767676767677, 'epoch': 0.05}\n",
      "{'loss': 1.0603, 'grad_norm': 0.3050898313522339, 'learning_rate': 0.00019636363636363636, 'epoch': 0.06}\n",
      "{'loss': 1.0614, 'grad_norm': 0.28000015020370483, 'learning_rate': 0.00019595959595959596, 'epoch': 0.06}\n",
      "{'loss': 1.0086, 'grad_norm': 0.28146395087242126, 'learning_rate': 0.00019555555555555556, 'epoch': 0.06}\n",
      "{'loss': 0.942, 'grad_norm': 0.26584354043006897, 'learning_rate': 0.00019515151515151516, 'epoch': 0.07}\n",
      "{'loss': 0.7912, 'grad_norm': 0.26628366112709045, 'learning_rate': 0.00019474747474747476, 'epoch': 0.07}\n",
      "{'loss': 1.287, 'grad_norm': 0.2954716980457306, 'learning_rate': 0.00019434343434343435, 'epoch': 0.08}\n",
      "{'loss': 1.1332, 'grad_norm': 0.27093350887298584, 'learning_rate': 0.00019393939393939395, 'epoch': 0.08}\n",
      "{'loss': 1.0221, 'grad_norm': 0.350841224193573, 'learning_rate': 0.00019353535353535355, 'epoch': 0.08}\n",
      "{'loss': 0.9911, 'grad_norm': 0.2793560028076172, 'learning_rate': 0.00019313131313131315, 'epoch': 0.09}\n",
      "{'loss': 1.0686, 'grad_norm': 0.3253811299800873, 'learning_rate': 0.00019272727272727274, 'epoch': 0.09}\n",
      "{'loss': 1.0184, 'grad_norm': 0.3408013582229614, 'learning_rate': 0.00019232323232323232, 'epoch': 0.1}\n",
      "{'loss': 1.0677, 'grad_norm': 0.2640942931175232, 'learning_rate': 0.00019191919191919191, 'epoch': 0.1}\n",
      "{'loss': 1.0775, 'grad_norm': 0.2840923070907593, 'learning_rate': 0.0001915151515151515, 'epoch': 0.1}\n",
      "{'loss': 0.8755, 'grad_norm': 0.2501833736896515, 'learning_rate': 0.00019111111111111114, 'epoch': 0.11}\n",
      "{'loss': 1.0138, 'grad_norm': 0.26282787322998047, 'learning_rate': 0.00019070707070707073, 'epoch': 0.11}\n",
      "{'loss': 1.0778, 'grad_norm': 0.29880291223526, 'learning_rate': 0.0001903030303030303, 'epoch': 0.12}\n",
      "{'loss': 0.9716, 'grad_norm': 0.26447373628616333, 'learning_rate': 0.0001898989898989899, 'epoch': 0.12}\n",
      "{'loss': 0.9308, 'grad_norm': 0.2713015675544739, 'learning_rate': 0.0001894949494949495, 'epoch': 0.12}\n",
      "{'loss': 0.9912, 'grad_norm': 0.263397753238678, 'learning_rate': 0.0001890909090909091, 'epoch': 0.13}\n",
      "{'loss': 0.9193, 'grad_norm': 0.25749334692955017, 'learning_rate': 0.0001886868686868687, 'epoch': 0.13}\n",
      "{'loss': 0.9969, 'grad_norm': 0.2660374343395233, 'learning_rate': 0.0001882828282828283, 'epoch': 0.14}\n",
      "{'loss': 1.0762, 'grad_norm': 0.28346848487854004, 'learning_rate': 0.0001878787878787879, 'epoch': 0.14}\n",
      "{'loss': 1.0919, 'grad_norm': 0.274187296628952, 'learning_rate': 0.0001874747474747475, 'epoch': 0.14}\n",
      "{'loss': 1.01, 'grad_norm': 0.2989098131656647, 'learning_rate': 0.0001870707070707071, 'epoch': 0.15}\n",
      "{'loss': 1.0598, 'grad_norm': 0.28250256180763245, 'learning_rate': 0.0001866666666666667, 'epoch': 0.15}\n",
      "{'loss': 1.1419, 'grad_norm': 0.2742801904678345, 'learning_rate': 0.00018626262626262628, 'epoch': 0.16}\n",
      "{'loss': 0.9569, 'grad_norm': 0.3051857650279999, 'learning_rate': 0.00018585858585858586, 'epoch': 0.16}\n",
      "{'loss': 1.2012, 'grad_norm': 0.2752961814403534, 'learning_rate': 0.00018545454545454545, 'epoch': 0.16}\n",
      "{'loss': 1.0039, 'grad_norm': 0.23827414214611053, 'learning_rate': 0.00018505050505050505, 'epoch': 0.17}\n",
      "{'loss': 1.0378, 'grad_norm': 0.2744739353656769, 'learning_rate': 0.00018464646464646465, 'epoch': 0.17}\n",
      "{'loss': 1.0565, 'grad_norm': 0.31260910630226135, 'learning_rate': 0.00018424242424242427, 'epoch': 0.18}\n",
      "{'loss': 1.0059, 'grad_norm': 0.2627756595611572, 'learning_rate': 0.00018383838383838384, 'epoch': 0.18}\n",
      "{'loss': 1.1329, 'grad_norm': 0.2958157956600189, 'learning_rate': 0.00018343434343434344, 'epoch': 0.18}\n",
      "{'loss': 1.0231, 'grad_norm': 0.26357099413871765, 'learning_rate': 0.00018303030303030304, 'epoch': 0.19}\n",
      "{'loss': 1.0368, 'grad_norm': 0.26480308175086975, 'learning_rate': 0.00018262626262626264, 'epoch': 0.19}\n",
      "{'loss': 0.8064, 'grad_norm': 0.2538083791732788, 'learning_rate': 0.00018222222222222224, 'epoch': 0.2}\n",
      "{'loss': 0.9933, 'grad_norm': 0.34137144684791565, 'learning_rate': 0.00018181818181818183, 'epoch': 0.2}\n",
      "{'loss': 1.1282, 'grad_norm': 0.27186766266822815, 'learning_rate': 0.0001814141414141414, 'epoch': 0.2}\n",
      "{'loss': 0.9446, 'grad_norm': 0.2488006204366684, 'learning_rate': 0.00018101010101010103, 'epoch': 0.21}\n",
      "{'loss': 0.9071, 'grad_norm': 0.2931256592273712, 'learning_rate': 0.00018060606060606063, 'epoch': 0.21}\n",
      "{'loss': 0.874, 'grad_norm': 0.2666167914867401, 'learning_rate': 0.00018020202020202023, 'epoch': 0.22}\n",
      "{'loss': 1.0968, 'grad_norm': 0.3127819299697876, 'learning_rate': 0.0001797979797979798, 'epoch': 0.22}\n",
      "{'loss': 0.9567, 'grad_norm': 0.2473980337381363, 'learning_rate': 0.0001793939393939394, 'epoch': 0.22}\n",
      "{'loss': 1.1853, 'grad_norm': 0.2932046949863434, 'learning_rate': 0.000178989898989899, 'epoch': 0.23}\n",
      "{'loss': 0.8664, 'grad_norm': 0.2520236372947693, 'learning_rate': 0.0001785858585858586, 'epoch': 0.23}\n",
      "{'loss': 0.89, 'grad_norm': 0.25381097197532654, 'learning_rate': 0.0001781818181818182, 'epoch': 0.24}\n",
      "{'loss': 0.9886, 'grad_norm': 0.25410938262939453, 'learning_rate': 0.00017777777777777779, 'epoch': 0.24}\n",
      "{'loss': 1.1404, 'grad_norm': 0.331358402967453, 'learning_rate': 0.00017737373737373738, 'epoch': 0.24}\n",
      "{'loss': 1.1497, 'grad_norm': 0.2738577127456665, 'learning_rate': 0.00017696969696969698, 'epoch': 0.25}\n",
      "{'loss': 0.9543, 'grad_norm': 0.26056748628616333, 'learning_rate': 0.00017656565656565658, 'epoch': 0.25}\n",
      "{'loss': 0.9395, 'grad_norm': 0.2820223867893219, 'learning_rate': 0.00017616161616161618, 'epoch': 0.26}\n",
      "{'loss': 0.9975, 'grad_norm': 0.2667521834373474, 'learning_rate': 0.00017575757575757578, 'epoch': 0.26}\n",
      "{'loss': 1.0985, 'grad_norm': 0.31490558385849, 'learning_rate': 0.00017535353535353535, 'epoch': 0.26}\n",
      "{'loss': 1.0773, 'grad_norm': 0.25049102306365967, 'learning_rate': 0.00017494949494949494, 'epoch': 0.27}\n",
      "{'loss': 1.0044, 'grad_norm': 0.26015469431877136, 'learning_rate': 0.00017454545454545454, 'epoch': 0.27}\n",
      "{'loss': 0.9312, 'grad_norm': 0.25140365958213806, 'learning_rate': 0.00017414141414141414, 'epoch': 0.28}\n",
      "{'loss': 1.0711, 'grad_norm': 0.3309503197669983, 'learning_rate': 0.00017373737373737377, 'epoch': 0.28}\n",
      "{'loss': 1.1876, 'grad_norm': 0.29488128423690796, 'learning_rate': 0.00017333333333333334, 'epoch': 0.28}\n",
      "{'loss': 1.1102, 'grad_norm': 0.3037022650241852, 'learning_rate': 0.00017292929292929293, 'epoch': 0.29}\n",
      "{'loss': 0.9407, 'grad_norm': 0.33468183875083923, 'learning_rate': 0.00017252525252525253, 'epoch': 0.29}\n",
      "{'loss': 1.1512, 'grad_norm': 0.29082709550857544, 'learning_rate': 0.00017212121212121213, 'epoch': 0.3}\n",
      "{'loss': 0.9079, 'grad_norm': 0.23345071077346802, 'learning_rate': 0.00017171717171717173, 'epoch': 0.3}\n",
      "{'loss': 0.9317, 'grad_norm': 0.2586683928966522, 'learning_rate': 0.00017131313131313133, 'epoch': 0.3}\n",
      "{'loss': 1.1033, 'grad_norm': 0.26311662793159485, 'learning_rate': 0.0001709090909090909, 'epoch': 0.31}\n",
      "{'loss': 1.0099, 'grad_norm': 0.2532307803630829, 'learning_rate': 0.00017050505050505052, 'epoch': 0.31}\n",
      "{'loss': 1.1198, 'grad_norm': 0.2571605443954468, 'learning_rate': 0.00017010101010101012, 'epoch': 0.32}\n",
      "{'loss': 0.9635, 'grad_norm': 0.26244211196899414, 'learning_rate': 0.00016969696969696972, 'epoch': 0.32}\n",
      "{'loss': 1.1515, 'grad_norm': 0.269624799489975, 'learning_rate': 0.00016929292929292932, 'epoch': 0.32}\n",
      "{'loss': 1.013, 'grad_norm': 0.26096096634864807, 'learning_rate': 0.00016888888888888889, 'epoch': 0.33}\n",
      "{'loss': 0.8723, 'grad_norm': 0.2910487651824951, 'learning_rate': 0.00016848484848484848, 'epoch': 0.33}\n",
      "{'loss': 1.0007, 'grad_norm': 0.26162025332450867, 'learning_rate': 0.00016808080808080808, 'epoch': 0.34}\n",
      "{'loss': 1.0752, 'grad_norm': 0.3052949905395508, 'learning_rate': 0.00016767676767676768, 'epoch': 0.34}\n",
      "{'loss': 0.8377, 'grad_norm': 0.27278777956962585, 'learning_rate': 0.00016727272727272728, 'epoch': 0.34}\n",
      "{'loss': 1.0435, 'grad_norm': 0.26837092638015747, 'learning_rate': 0.00016686868686868688, 'epoch': 0.35}\n",
      "{'loss': 0.9017, 'grad_norm': 0.2938951551914215, 'learning_rate': 0.00016646464646464647, 'epoch': 0.35}\n",
      "{'loss': 1.0054, 'grad_norm': 0.24834398925304413, 'learning_rate': 0.00016606060606060607, 'epoch': 0.36}\n",
      "{'loss': 0.8934, 'grad_norm': 0.2963956296443939, 'learning_rate': 0.00016565656565656567, 'epoch': 0.36}\n",
      "{'loss': 0.785, 'grad_norm': 0.22034457325935364, 'learning_rate': 0.00016525252525252527, 'epoch': 0.36}\n",
      "{'loss': 1.0424, 'grad_norm': 0.2731887400150299, 'learning_rate': 0.00016484848484848487, 'epoch': 0.37}\n",
      "{'loss': 0.9748, 'grad_norm': 0.2898293435573578, 'learning_rate': 0.00016444444444444444, 'epoch': 0.37}\n",
      "{'loss': 0.9963, 'grad_norm': 0.24603518843650818, 'learning_rate': 0.00016404040404040403, 'epoch': 0.38}\n",
      "{'loss': 0.9929, 'grad_norm': 0.25920093059539795, 'learning_rate': 0.00016363636363636366, 'epoch': 0.38}\n",
      "{'loss': 1.1148, 'grad_norm': 0.31247222423553467, 'learning_rate': 0.00016323232323232326, 'epoch': 0.38}\n",
      "{'loss': 0.9157, 'grad_norm': 0.24099037051200867, 'learning_rate': 0.00016282828282828283, 'epoch': 0.39}\n",
      "{'loss': 0.8509, 'grad_norm': 0.21698938310146332, 'learning_rate': 0.00016242424242424243, 'epoch': 0.39}\n",
      "{'loss': 0.9022, 'grad_norm': 0.22491014003753662, 'learning_rate': 0.00016202020202020202, 'epoch': 0.4}\n",
      "{'loss': 1.0231, 'grad_norm': 0.2676429748535156, 'learning_rate': 0.00016161616161616162, 'epoch': 0.4}\n",
      "{'loss': 1.0365, 'grad_norm': 0.28871673345565796, 'learning_rate': 0.00016121212121212122, 'epoch': 0.4}\n",
      "{'loss': 1.163, 'grad_norm': 0.3426692485809326, 'learning_rate': 0.00016080808080808082, 'epoch': 0.41}\n",
      "{'loss': 0.9519, 'grad_norm': 0.24575552344322205, 'learning_rate': 0.0001604040404040404, 'epoch': 0.41}\n",
      "{'loss': 1.0697, 'grad_norm': 0.28341996669769287, 'learning_rate': 0.00016, 'epoch': 0.42}\n",
      "{'loss': 0.9356, 'grad_norm': 0.2773744463920593, 'learning_rate': 0.0001595959595959596, 'epoch': 0.42}\n",
      "{'loss': 0.9708, 'grad_norm': 0.25426235795021057, 'learning_rate': 0.0001591919191919192, 'epoch': 0.42}\n",
      "{'loss': 1.0532, 'grad_norm': 0.2564290165901184, 'learning_rate': 0.0001587878787878788, 'epoch': 0.43}\n",
      "{'loss': 1.0901, 'grad_norm': 0.2604949176311493, 'learning_rate': 0.00015838383838383838, 'epoch': 0.43}\n",
      "{'loss': 1.1227, 'grad_norm': 0.26579272747039795, 'learning_rate': 0.00015797979797979798, 'epoch': 0.44}\n",
      "{'loss': 1.1489, 'grad_norm': 0.3189639449119568, 'learning_rate': 0.00015757575757575757, 'epoch': 0.44}\n",
      "{'loss': 0.986, 'grad_norm': 0.2604120373725891, 'learning_rate': 0.00015717171717171717, 'epoch': 0.44}\n",
      "{'loss': 1.0664, 'grad_norm': 0.26491403579711914, 'learning_rate': 0.0001567676767676768, 'epoch': 0.45}\n",
      "{'loss': 0.8607, 'grad_norm': 0.3064737319946289, 'learning_rate': 0.00015636363636363637, 'epoch': 0.45}\n",
      "{'loss': 0.867, 'grad_norm': 0.24049240350723267, 'learning_rate': 0.00015595959595959597, 'epoch': 0.46}\n",
      "{'loss': 0.9417, 'grad_norm': 0.26108336448669434, 'learning_rate': 0.00015555555555555556, 'epoch': 0.46}\n",
      "{'loss': 0.9246, 'grad_norm': 0.28977662324905396, 'learning_rate': 0.00015515151515151516, 'epoch': 0.46}\n",
      "{'loss': 1.0097, 'grad_norm': 0.2842887341976166, 'learning_rate': 0.00015474747474747476, 'epoch': 0.47}\n",
      "{'loss': 1.0912, 'grad_norm': 0.2579113841056824, 'learning_rate': 0.00015434343434343436, 'epoch': 0.47}\n",
      "{'loss': 0.9982, 'grad_norm': 0.2445223033428192, 'learning_rate': 0.00015393939393939393, 'epoch': 0.48}\n",
      "{'loss': 0.8287, 'grad_norm': 0.24831008911132812, 'learning_rate': 0.00015353535353535353, 'epoch': 0.48}\n",
      "{'loss': 0.9336, 'grad_norm': 0.2435573935508728, 'learning_rate': 0.00015313131313131315, 'epoch': 0.48}\n",
      "{'loss': 1.0424, 'grad_norm': 0.28872692584991455, 'learning_rate': 0.00015272727272727275, 'epoch': 0.49}\n",
      "{'loss': 1.0665, 'grad_norm': 0.26122725009918213, 'learning_rate': 0.00015232323232323235, 'epoch': 0.49}\n",
      "{'loss': 0.8619, 'grad_norm': 0.2751725912094116, 'learning_rate': 0.00015191919191919192, 'epoch': 0.5}\n",
      "{'loss': 0.9964, 'grad_norm': 0.2442200928926468, 'learning_rate': 0.00015151515151515152, 'epoch': 0.5}\n",
      "{'loss': 1.0859, 'grad_norm': 0.28077587485313416, 'learning_rate': 0.0001511111111111111, 'epoch': 0.5}\n",
      "{'loss': 1.1277, 'grad_norm': 0.31797826290130615, 'learning_rate': 0.0001507070707070707, 'epoch': 0.51}\n",
      "{'loss': 0.9368, 'grad_norm': 0.2721427381038666, 'learning_rate': 0.0001503030303030303, 'epoch': 0.51}\n",
      "{'loss': 1.1755, 'grad_norm': 0.2901131212711334, 'learning_rate': 0.0001498989898989899, 'epoch': 0.52}\n",
      "{'loss': 1.1001, 'grad_norm': 0.240873321890831, 'learning_rate': 0.0001494949494949495, 'epoch': 0.52}\n",
      "{'loss': 1.0524, 'grad_norm': 0.2643979787826538, 'learning_rate': 0.0001490909090909091, 'epoch': 0.52}\n",
      "{'loss': 0.798, 'grad_norm': 0.22770319879055023, 'learning_rate': 0.0001486868686868687, 'epoch': 0.53}\n",
      "{'loss': 0.9685, 'grad_norm': 0.28827765583992004, 'learning_rate': 0.0001482828282828283, 'epoch': 0.53}\n",
      "{'loss': 0.822, 'grad_norm': 0.2509165108203888, 'learning_rate': 0.0001478787878787879, 'epoch': 0.54}\n",
      "{'loss': 0.9274, 'grad_norm': 0.26123929023742676, 'learning_rate': 0.00014747474747474747, 'epoch': 0.54}\n",
      "{'loss': 0.9836, 'grad_norm': 0.27611011266708374, 'learning_rate': 0.00014707070707070706, 'epoch': 0.54}\n",
      "{'loss': 1.0023, 'grad_norm': 0.26926836371421814, 'learning_rate': 0.00014666666666666666, 'epoch': 0.55}\n",
      "{'loss': 0.9994, 'grad_norm': 0.22490540146827698, 'learning_rate': 0.0001462626262626263, 'epoch': 0.55}\n",
      "{'loss': 0.903, 'grad_norm': 0.2818419635295868, 'learning_rate': 0.00014585858585858586, 'epoch': 0.56}\n",
      "{'loss': 0.8233, 'grad_norm': 0.2620595097541809, 'learning_rate': 0.00014545454545454546, 'epoch': 0.56}\n",
      "{'loss': 0.8393, 'grad_norm': 0.25759294629096985, 'learning_rate': 0.00014505050505050505, 'epoch': 0.56}\n",
      "{'loss': 0.9939, 'grad_norm': 0.2542378902435303, 'learning_rate': 0.00014464646464646465, 'epoch': 0.57}\n",
      "{'loss': 1.0474, 'grad_norm': 0.2702077329158783, 'learning_rate': 0.00014424242424242425, 'epoch': 0.57}\n",
      "{'loss': 0.8779, 'grad_norm': 0.3180796802043915, 'learning_rate': 0.00014383838383838385, 'epoch': 0.58}\n",
      "{'loss': 0.8988, 'grad_norm': 0.2787013649940491, 'learning_rate': 0.00014343434343434342, 'epoch': 0.58}\n",
      "{'loss': 0.9832, 'grad_norm': 0.3221924901008606, 'learning_rate': 0.00014303030303030304, 'epoch': 0.58}\n",
      "{'loss': 0.9699, 'grad_norm': 0.26452019810676575, 'learning_rate': 0.00014262626262626264, 'epoch': 0.59}\n",
      "{'loss': 0.8827, 'grad_norm': 0.2739226520061493, 'learning_rate': 0.00014222222222222224, 'epoch': 0.59}\n",
      "{'loss': 0.7839, 'grad_norm': 0.29652518033981323, 'learning_rate': 0.00014181818181818184, 'epoch': 0.6}\n",
      "{'loss': 1.0157, 'grad_norm': 0.28841087222099304, 'learning_rate': 0.0001414141414141414, 'epoch': 0.6}\n",
      "{'loss': 1.0603, 'grad_norm': 0.2469678372144699, 'learning_rate': 0.000141010101010101, 'epoch': 0.6}\n",
      "{'loss': 1.1801, 'grad_norm': 0.25733885169029236, 'learning_rate': 0.0001406060606060606, 'epoch': 0.61}\n",
      "{'loss': 1.0375, 'grad_norm': 0.3099748492240906, 'learning_rate': 0.0001402020202020202, 'epoch': 0.61}\n",
      "{'loss': 1.0539, 'grad_norm': 0.26531946659088135, 'learning_rate': 0.0001397979797979798, 'epoch': 0.62}\n",
      "{'loss': 0.9036, 'grad_norm': 0.2423827052116394, 'learning_rate': 0.0001393939393939394, 'epoch': 0.62}\n",
      "{'loss': 1.0791, 'grad_norm': 0.27836722135543823, 'learning_rate': 0.000138989898989899, 'epoch': 0.62}\n",
      "{'loss': 0.7893, 'grad_norm': 0.2270503044128418, 'learning_rate': 0.0001385858585858586, 'epoch': 0.63}\n",
      "{'loss': 1.0414, 'grad_norm': 0.252269446849823, 'learning_rate': 0.0001381818181818182, 'epoch': 0.63}\n",
      "{'loss': 0.979, 'grad_norm': 0.2500433325767517, 'learning_rate': 0.0001377777777777778, 'epoch': 0.64}\n",
      "{'loss': 0.9823, 'grad_norm': 0.2492089569568634, 'learning_rate': 0.0001373737373737374, 'epoch': 0.64}\n",
      "{'loss': 0.892, 'grad_norm': 0.2395602911710739, 'learning_rate': 0.00013696969696969696, 'epoch': 0.64}\n",
      "{'loss': 0.9499, 'grad_norm': 0.23952050507068634, 'learning_rate': 0.00013656565656565656, 'epoch': 0.65}\n",
      "{'loss': 1.0555, 'grad_norm': 0.2778460681438446, 'learning_rate': 0.00013616161616161618, 'epoch': 0.65}\n",
      "{'loss': 1.0071, 'grad_norm': 0.2617553472518921, 'learning_rate': 0.00013575757575757578, 'epoch': 0.66}\n",
      "{'loss': 1.2023, 'grad_norm': 0.2721719443798065, 'learning_rate': 0.00013535353535353538, 'epoch': 0.66}\n",
      "{'loss': 0.9297, 'grad_norm': 0.2827543318271637, 'learning_rate': 0.00013494949494949495, 'epoch': 0.66}\n",
      "{'loss': 1.0213, 'grad_norm': 0.2799731194972992, 'learning_rate': 0.00013454545454545455, 'epoch': 0.67}\n",
      "{'loss': 1.0509, 'grad_norm': 0.27092444896698, 'learning_rate': 0.00013414141414141414, 'epoch': 0.67}\n",
      "{'loss': 1.0963, 'grad_norm': 0.2820524275302887, 'learning_rate': 0.00013373737373737374, 'epoch': 0.68}\n",
      "{'loss': 0.7888, 'grad_norm': 0.26410260796546936, 'learning_rate': 0.00013333333333333334, 'epoch': 0.68}\n",
      "{'loss': 0.9856, 'grad_norm': 0.25866878032684326, 'learning_rate': 0.00013292929292929294, 'epoch': 0.68}\n",
      "{'loss': 0.9681, 'grad_norm': 0.2599627673625946, 'learning_rate': 0.00013252525252525254, 'epoch': 0.69}\n",
      "{'loss': 1.269, 'grad_norm': 0.2972125709056854, 'learning_rate': 0.00013212121212121213, 'epoch': 0.69}\n",
      "{'loss': 1.066, 'grad_norm': 0.31469041109085083, 'learning_rate': 0.00013171717171717173, 'epoch': 0.7}\n",
      "{'loss': 0.8888, 'grad_norm': 0.27095696330070496, 'learning_rate': 0.00013131313131313133, 'epoch': 0.7}\n",
      "{'loss': 1.1163, 'grad_norm': 0.25445273518562317, 'learning_rate': 0.00013090909090909093, 'epoch': 0.7}\n",
      "{'loss': 1.2141, 'grad_norm': 0.34510672092437744, 'learning_rate': 0.0001305050505050505, 'epoch': 0.71}\n",
      "{'loss': 0.9663, 'grad_norm': 0.2631739675998688, 'learning_rate': 0.0001301010101010101, 'epoch': 0.71}\n",
      "{'loss': 1.0236, 'grad_norm': 0.2811201512813568, 'learning_rate': 0.0001296969696969697, 'epoch': 0.72}\n",
      "{'loss': 0.8794, 'grad_norm': 0.24825504422187805, 'learning_rate': 0.00012929292929292932, 'epoch': 0.72}\n",
      "{'loss': 0.8974, 'grad_norm': 0.25293946266174316, 'learning_rate': 0.00012888888888888892, 'epoch': 0.72}\n",
      "{'loss': 0.8551, 'grad_norm': 0.26709631085395813, 'learning_rate': 0.0001284848484848485, 'epoch': 0.73}\n",
      "{'loss': 0.9449, 'grad_norm': 0.27194467186927795, 'learning_rate': 0.00012808080808080809, 'epoch': 0.73}\n",
      "{'loss': 1.0519, 'grad_norm': 0.30341672897338867, 'learning_rate': 0.00012767676767676768, 'epoch': 0.74}\n",
      "{'loss': 1.1044, 'grad_norm': 0.28210482001304626, 'learning_rate': 0.00012727272727272728, 'epoch': 0.74}\n",
      "{'loss': 0.8822, 'grad_norm': 0.2717773914337158, 'learning_rate': 0.00012686868686868688, 'epoch': 0.74}\n",
      "{'loss': 0.9186, 'grad_norm': 0.26438286900520325, 'learning_rate': 0.00012646464646464645, 'epoch': 0.75}\n",
      "{'loss': 1.1768, 'grad_norm': 0.25652989745140076, 'learning_rate': 0.00012606060606060605, 'epoch': 0.75}\n",
      "{'loss': 1.0693, 'grad_norm': 0.26836416125297546, 'learning_rate': 0.00012565656565656567, 'epoch': 0.76}\n",
      "{'loss': 0.9244, 'grad_norm': 0.24217426776885986, 'learning_rate': 0.00012525252525252527, 'epoch': 0.76}\n",
      "{'loss': 1.0185, 'grad_norm': 0.2694929540157318, 'learning_rate': 0.00012484848484848487, 'epoch': 0.76}\n",
      "{'loss': 0.8758, 'grad_norm': 0.2839827537536621, 'learning_rate': 0.00012444444444444444, 'epoch': 0.77}\n",
      "{'loss': 0.7769, 'grad_norm': 0.2937108278274536, 'learning_rate': 0.00012404040404040404, 'epoch': 0.77}\n",
      "{'loss': 1.0685, 'grad_norm': 0.31752556562423706, 'learning_rate': 0.00012363636363636364, 'epoch': 0.78}\n",
      "{'loss': 0.9722, 'grad_norm': 0.26574233174324036, 'learning_rate': 0.00012323232323232323, 'epoch': 0.78}\n",
      "{'loss': 0.9802, 'grad_norm': 0.289171427488327, 'learning_rate': 0.00012282828282828283, 'epoch': 0.78}\n",
      "{'loss': 1.0821, 'grad_norm': 0.3122731149196625, 'learning_rate': 0.00012242424242424243, 'epoch': 0.79}\n",
      "{'loss': 0.8172, 'grad_norm': 0.2834780812263489, 'learning_rate': 0.00012202020202020204, 'epoch': 0.79}\n",
      "{'loss': 0.9495, 'grad_norm': 0.2604948580265045, 'learning_rate': 0.00012161616161616162, 'epoch': 0.8}\n",
      "{'loss': 0.9649, 'grad_norm': 0.24593551456928253, 'learning_rate': 0.00012121212121212122, 'epoch': 0.8}\n",
      "{'loss': 1.0996, 'grad_norm': 0.26406753063201904, 'learning_rate': 0.00012080808080808082, 'epoch': 0.8}\n",
      "{'loss': 1.0506, 'grad_norm': 0.2510004937648773, 'learning_rate': 0.0001204040404040404, 'epoch': 0.81}\n",
      "{'loss': 0.8764, 'grad_norm': 0.2570507824420929, 'learning_rate': 0.00012, 'epoch': 0.81}\n",
      "{'loss': 0.9393, 'grad_norm': 0.29294756054878235, 'learning_rate': 0.0001195959595959596, 'epoch': 0.82}\n",
      "{'loss': 0.8392, 'grad_norm': 0.28282275795936584, 'learning_rate': 0.00011919191919191919, 'epoch': 0.82}\n",
      "{'loss': 0.9511, 'grad_norm': 0.26065388321876526, 'learning_rate': 0.0001187878787878788, 'epoch': 0.82}\n",
      "{'loss': 0.7954, 'grad_norm': 0.24401012063026428, 'learning_rate': 0.0001183838383838384, 'epoch': 0.83}\n",
      "{'loss': 1.0692, 'grad_norm': 0.30855610966682434, 'learning_rate': 0.00011797979797979799, 'epoch': 0.83}\n",
      "{'loss': 1.086, 'grad_norm': 0.28587934374809265, 'learning_rate': 0.00011757575757575758, 'epoch': 0.84}\n",
      "{'loss': 0.8654, 'grad_norm': 0.2900451123714447, 'learning_rate': 0.00011717171717171717, 'epoch': 0.84}\n",
      "{'loss': 0.9897, 'grad_norm': 0.2685021162033081, 'learning_rate': 0.00011676767676767677, 'epoch': 0.84}\n",
      "{'loss': 1.0309, 'grad_norm': 0.2808912694454193, 'learning_rate': 0.00011636363636363636, 'epoch': 0.85}\n",
      "{'loss': 1.0296, 'grad_norm': 0.2674299478530884, 'learning_rate': 0.00011595959595959596, 'epoch': 0.85}\n",
      "{'loss': 1.0678, 'grad_norm': 0.27559250593185425, 'learning_rate': 0.00011555555555555555, 'epoch': 0.86}\n",
      "{'loss': 0.9844, 'grad_norm': 0.27177464962005615, 'learning_rate': 0.00011515151515151516, 'epoch': 0.86}\n",
      "{'loss': 1.0433, 'grad_norm': 0.2543864846229553, 'learning_rate': 0.00011474747474747476, 'epoch': 0.86}\n",
      "{'loss': 1.1132, 'grad_norm': 0.2620302140712738, 'learning_rate': 0.00011434343434343435, 'epoch': 0.87}\n",
      "{'loss': 0.9908, 'grad_norm': 0.2919307351112366, 'learning_rate': 0.00011393939393939394, 'epoch': 0.87}\n",
      "{'loss': 1.0491, 'grad_norm': 0.28384992480278015, 'learning_rate': 0.00011353535353535354, 'epoch': 0.88}\n",
      "{'loss': 1.0673, 'grad_norm': 0.26680588722229004, 'learning_rate': 0.00011313131313131313, 'epoch': 0.88}\n",
      "{'loss': 1.0162, 'grad_norm': 0.2523479163646698, 'learning_rate': 0.00011272727272727272, 'epoch': 0.88}\n",
      "{'loss': 0.9838, 'grad_norm': 0.24953651428222656, 'learning_rate': 0.00011232323232323232, 'epoch': 0.89}\n",
      "{'loss': 1.1628, 'grad_norm': 0.3105087876319885, 'learning_rate': 0.00011191919191919193, 'epoch': 0.89}\n",
      "{'loss': 0.9034, 'grad_norm': 0.2474413365125656, 'learning_rate': 0.00011151515151515153, 'epoch': 0.9}\n",
      "{'loss': 0.9421, 'grad_norm': 0.23994599282741547, 'learning_rate': 0.00011111111111111112, 'epoch': 0.9}\n",
      "{'loss': 1.031, 'grad_norm': 0.24193987250328064, 'learning_rate': 0.00011070707070707071, 'epoch': 0.9}\n",
      "{'loss': 1.0214, 'grad_norm': 0.27735477685928345, 'learning_rate': 0.00011030303030303031, 'epoch': 0.91}\n",
      "{'loss': 0.8342, 'grad_norm': 0.2560582756996155, 'learning_rate': 0.0001098989898989899, 'epoch': 0.91}\n",
      "{'loss': 0.8529, 'grad_norm': 0.2810837924480438, 'learning_rate': 0.0001094949494949495, 'epoch': 0.92}\n",
      "{'loss': 0.8708, 'grad_norm': 0.24745412170886993, 'learning_rate': 0.00010909090909090909, 'epoch': 0.92}\n",
      "{'loss': 0.8748, 'grad_norm': 0.2601678669452667, 'learning_rate': 0.00010868686868686868, 'epoch': 0.92}\n",
      "{'loss': 0.9819, 'grad_norm': 0.30280131101608276, 'learning_rate': 0.0001082828282828283, 'epoch': 0.93}\n",
      "{'loss': 0.9695, 'grad_norm': 0.29799410700798035, 'learning_rate': 0.00010787878787878789, 'epoch': 0.93}\n",
      "{'loss': 0.9071, 'grad_norm': 0.290429949760437, 'learning_rate': 0.00010747474747474748, 'epoch': 0.94}\n",
      "{'loss': 0.9119, 'grad_norm': 0.26245632767677307, 'learning_rate': 0.00010707070707070708, 'epoch': 0.94}\n",
      "{'loss': 0.8897, 'grad_norm': 0.27938365936279297, 'learning_rate': 0.00010666666666666667, 'epoch': 0.94}\n",
      "{'loss': 0.7793, 'grad_norm': 0.23473848402500153, 'learning_rate': 0.00010626262626262626, 'epoch': 0.95}\n",
      "{'loss': 0.9179, 'grad_norm': 0.2635546326637268, 'learning_rate': 0.00010585858585858586, 'epoch': 0.95}\n",
      "{'loss': 0.9166, 'grad_norm': 0.25310420989990234, 'learning_rate': 0.00010545454545454545, 'epoch': 0.96}\n",
      "{'loss': 1.0433, 'grad_norm': 0.3015272617340088, 'learning_rate': 0.00010505050505050507, 'epoch': 0.96}\n",
      "{'loss': 1.0944, 'grad_norm': 0.3064992129802704, 'learning_rate': 0.00010464646464646466, 'epoch': 0.96}\n",
      "{'loss': 1.043, 'grad_norm': 0.2787345051765442, 'learning_rate': 0.00010424242424242425, 'epoch': 0.97}\n",
      "{'loss': 1.0243, 'grad_norm': 0.29455098509788513, 'learning_rate': 0.00010383838383838385, 'epoch': 0.97}\n",
      "{'loss': 0.8646, 'grad_norm': 0.27927741408348083, 'learning_rate': 0.00010343434343434344, 'epoch': 0.98}\n",
      "{'loss': 1.0054, 'grad_norm': 0.2494671791791916, 'learning_rate': 0.00010303030303030303, 'epoch': 0.98}\n",
      "{'loss': 0.966, 'grad_norm': 0.29353564977645874, 'learning_rate': 0.00010262626262626263, 'epoch': 0.98}\n",
      "{'loss': 0.9986, 'grad_norm': 0.2879904806613922, 'learning_rate': 0.00010222222222222222, 'epoch': 0.99}\n",
      "{'loss': 0.9679, 'grad_norm': 0.25191864371299744, 'learning_rate': 0.00010181818181818181, 'epoch': 0.99}\n",
      "{'loss': 1.0304, 'grad_norm': 0.29981955885887146, 'learning_rate': 0.00010141414141414143, 'epoch': 1.0}\n",
      "{'loss': 0.9391, 'grad_norm': 0.26482290029525757, 'learning_rate': 0.00010101010101010102, 'epoch': 1.0}\n",
      "{'loss': 0.7949, 'grad_norm': 0.26845279335975647, 'learning_rate': 0.00010060606060606062, 'epoch': 1.0}\n",
      "{'loss': 0.9351, 'grad_norm': 0.24902862310409546, 'learning_rate': 0.0001002020202020202, 'epoch': 1.01}\n",
      "{'loss': 1.022, 'grad_norm': 0.25644779205322266, 'learning_rate': 9.97979797979798e-05, 'epoch': 1.01}\n",
      "{'loss': 0.7108, 'grad_norm': 0.2623470723628998, 'learning_rate': 9.939393939393939e-05, 'epoch': 1.02}\n",
      "{'loss': 0.9834, 'grad_norm': 0.28008508682250977, 'learning_rate': 9.8989898989899e-05, 'epoch': 1.02}\n",
      "{'loss': 0.7718, 'grad_norm': 0.2579578161239624, 'learning_rate': 9.85858585858586e-05, 'epoch': 1.02}\n",
      "{'loss': 0.9207, 'grad_norm': 0.30353185534477234, 'learning_rate': 9.818181818181818e-05, 'epoch': 1.03}\n",
      "{'loss': 0.9931, 'grad_norm': 0.2877969443798065, 'learning_rate': 9.777777777777778e-05, 'epoch': 1.03}\n",
      "{'loss': 0.6204, 'grad_norm': 0.24990501999855042, 'learning_rate': 9.737373737373738e-05, 'epoch': 1.04}\n",
      "{'loss': 0.943, 'grad_norm': 0.29857414960861206, 'learning_rate': 9.696969696969698e-05, 'epoch': 1.04}\n",
      "{'loss': 0.8354, 'grad_norm': 0.28398653864860535, 'learning_rate': 9.656565656565657e-05, 'epoch': 1.04}\n",
      "{'loss': 0.7411, 'grad_norm': 0.268768846988678, 'learning_rate': 9.616161616161616e-05, 'epoch': 1.05}\n",
      "{'loss': 0.7374, 'grad_norm': 0.28509971499443054, 'learning_rate': 9.575757575757576e-05, 'epoch': 1.05}\n",
      "{'loss': 0.8873, 'grad_norm': 0.29226961731910706, 'learning_rate': 9.535353535353537e-05, 'epoch': 1.06}\n",
      "{'loss': 0.7532, 'grad_norm': 0.28665587306022644, 'learning_rate': 9.494949494949495e-05, 'epoch': 1.06}\n",
      "{'loss': 0.7841, 'grad_norm': 0.2647272050380707, 'learning_rate': 9.454545454545455e-05, 'epoch': 1.06}\n",
      "{'loss': 0.8084, 'grad_norm': 0.2733697295188904, 'learning_rate': 9.414141414141415e-05, 'epoch': 1.07}\n",
      "{'loss': 0.8486, 'grad_norm': 0.2815745770931244, 'learning_rate': 9.373737373737375e-05, 'epoch': 1.07}\n",
      "{'loss': 0.8225, 'grad_norm': 0.28463539481163025, 'learning_rate': 9.333333333333334e-05, 'epoch': 1.08}\n",
      "{'loss': 0.917, 'grad_norm': 0.29389435052871704, 'learning_rate': 9.292929292929293e-05, 'epoch': 1.08}\n",
      "{'loss': 0.9326, 'grad_norm': 0.30691421031951904, 'learning_rate': 9.252525252525253e-05, 'epoch': 1.08}\n",
      "{'loss': 0.8864, 'grad_norm': 0.30412614345550537, 'learning_rate': 9.212121212121214e-05, 'epoch': 1.09}\n",
      "{'loss': 0.7041, 'grad_norm': 0.28576040267944336, 'learning_rate': 9.171717171717172e-05, 'epoch': 1.09}\n",
      "{'loss': 0.6765, 'grad_norm': 0.2592948377132416, 'learning_rate': 9.131313131313132e-05, 'epoch': 1.1}\n",
      "{'loss': 0.8633, 'grad_norm': 0.3041772246360779, 'learning_rate': 9.090909090909092e-05, 'epoch': 1.1}\n",
      "{'loss': 0.6954, 'grad_norm': 0.2904781699180603, 'learning_rate': 9.050505050505052e-05, 'epoch': 1.1}\n",
      "{'loss': 0.7189, 'grad_norm': 0.2642304003238678, 'learning_rate': 9.010101010101011e-05, 'epoch': 1.11}\n",
      "{'loss': 0.9405, 'grad_norm': 0.27634119987487793, 'learning_rate': 8.96969696969697e-05, 'epoch': 1.11}\n",
      "{'loss': 0.7657, 'grad_norm': 0.27918630838394165, 'learning_rate': 8.92929292929293e-05, 'epoch': 1.12}\n",
      "{'loss': 0.7599, 'grad_norm': 0.2576196789741516, 'learning_rate': 8.888888888888889e-05, 'epoch': 1.12}\n",
      "{'loss': 0.9805, 'grad_norm': 0.3199186325073242, 'learning_rate': 8.848484848484849e-05, 'epoch': 1.12}\n",
      "{'loss': 0.7065, 'grad_norm': 0.30355706810951233, 'learning_rate': 8.808080808080809e-05, 'epoch': 1.13}\n",
      "{'loss': 0.8295, 'grad_norm': 0.2894194424152374, 'learning_rate': 8.767676767676767e-05, 'epoch': 1.13}\n",
      "{'loss': 0.7973, 'grad_norm': 0.26872992515563965, 'learning_rate': 8.727272727272727e-05, 'epoch': 1.14}\n",
      "{'loss': 0.7046, 'grad_norm': 0.2800293266773224, 'learning_rate': 8.686868686868688e-05, 'epoch': 1.14}\n",
      "{'loss': 0.8553, 'grad_norm': 0.3380471169948578, 'learning_rate': 8.646464646464647e-05, 'epoch': 1.14}\n",
      "{'loss': 0.9103, 'grad_norm': 0.28569331765174866, 'learning_rate': 8.606060606060606e-05, 'epoch': 1.15}\n",
      "{'loss': 0.8004, 'grad_norm': 0.3222741186618805, 'learning_rate': 8.565656565656566e-05, 'epoch': 1.15}\n",
      "{'loss': 0.7835, 'grad_norm': 0.2669484317302704, 'learning_rate': 8.525252525252526e-05, 'epoch': 1.16}\n",
      "{'loss': 0.7125, 'grad_norm': 0.2453971803188324, 'learning_rate': 8.484848484848486e-05, 'epoch': 1.16}\n",
      "{'loss': 0.9228, 'grad_norm': 0.30852359533309937, 'learning_rate': 8.444444444444444e-05, 'epoch': 1.16}\n",
      "{'loss': 0.7004, 'grad_norm': 0.3011647164821625, 'learning_rate': 8.404040404040404e-05, 'epoch': 1.17}\n",
      "{'loss': 0.8644, 'grad_norm': 0.29535824060440063, 'learning_rate': 8.363636363636364e-05, 'epoch': 1.17}\n",
      "{'loss': 0.8984, 'grad_norm': 0.2671830952167511, 'learning_rate': 8.323232323232324e-05, 'epoch': 1.18}\n",
      "{'loss': 0.9019, 'grad_norm': 0.32776710391044617, 'learning_rate': 8.282828282828283e-05, 'epoch': 1.18}\n",
      "{'loss': 0.8174, 'grad_norm': 0.28696322441101074, 'learning_rate': 8.242424242424243e-05, 'epoch': 1.18}\n",
      "{'loss': 0.8946, 'grad_norm': 0.29922956228256226, 'learning_rate': 8.202020202020202e-05, 'epoch': 1.19}\n",
      "{'loss': 0.8617, 'grad_norm': 0.3286900818347931, 'learning_rate': 8.161616161616163e-05, 'epoch': 1.19}\n",
      "{'loss': 0.8278, 'grad_norm': 0.32590967416763306, 'learning_rate': 8.121212121212121e-05, 'epoch': 1.2}\n",
      "{'loss': 0.8499, 'grad_norm': 0.31273406744003296, 'learning_rate': 8.080808080808081e-05, 'epoch': 1.2}\n",
      "{'loss': 0.7496, 'grad_norm': 0.2846556603908539, 'learning_rate': 8.040404040404041e-05, 'epoch': 1.2}\n",
      "{'loss': 0.7373, 'grad_norm': 0.29126253724098206, 'learning_rate': 8e-05, 'epoch': 1.21}\n",
      "{'loss': 0.7179, 'grad_norm': 0.2793411612510681, 'learning_rate': 7.95959595959596e-05, 'epoch': 1.21}\n",
      "{'loss': 0.8271, 'grad_norm': 0.3182835280895233, 'learning_rate': 7.919191919191919e-05, 'epoch': 1.22}\n",
      "{'loss': 0.9632, 'grad_norm': 0.3020727038383484, 'learning_rate': 7.878787878787879e-05, 'epoch': 1.22}\n",
      "{'loss': 0.8242, 'grad_norm': 0.2925877869129181, 'learning_rate': 7.83838383838384e-05, 'epoch': 1.22}\n",
      "{'loss': 0.8836, 'grad_norm': 0.35103318095207214, 'learning_rate': 7.797979797979798e-05, 'epoch': 1.23}\n",
      "{'loss': 0.7807, 'grad_norm': 0.31553828716278076, 'learning_rate': 7.757575757575758e-05, 'epoch': 1.23}\n",
      "{'loss': 0.7905, 'grad_norm': 0.30148565769195557, 'learning_rate': 7.717171717171718e-05, 'epoch': 1.24}\n",
      "{'loss': 0.8334, 'grad_norm': 0.3198907673358917, 'learning_rate': 7.676767676767676e-05, 'epoch': 1.24}\n",
      "{'loss': 0.9154, 'grad_norm': 0.3805258870124817, 'learning_rate': 7.636363636363637e-05, 'epoch': 1.24}\n",
      "{'loss': 0.6322, 'grad_norm': 0.28702330589294434, 'learning_rate': 7.595959595959596e-05, 'epoch': 1.25}\n",
      "{'loss': 0.8517, 'grad_norm': 0.31014683842658997, 'learning_rate': 7.555555555555556e-05, 'epoch': 1.25}\n",
      "{'loss': 0.8645, 'grad_norm': 0.31034210324287415, 'learning_rate': 7.515151515151515e-05, 'epoch': 1.26}\n",
      "{'loss': 0.7911, 'grad_norm': 0.3496059775352478, 'learning_rate': 7.474747474747475e-05, 'epoch': 1.26}\n",
      "{'loss': 0.8694, 'grad_norm': 0.33401885628700256, 'learning_rate': 7.434343434343435e-05, 'epoch': 1.26}\n",
      "{'loss': 0.8124, 'grad_norm': 0.30788394808769226, 'learning_rate': 7.393939393939395e-05, 'epoch': 1.27}\n",
      "{'loss': 0.9312, 'grad_norm': 0.3004783093929291, 'learning_rate': 7.353535353535353e-05, 'epoch': 1.27}\n",
      "{'loss': 0.747, 'grad_norm': 0.3210897147655487, 'learning_rate': 7.313131313131314e-05, 'epoch': 1.28}\n",
      "{'loss': 0.7629, 'grad_norm': 0.3131040036678314, 'learning_rate': 7.272727272727273e-05, 'epoch': 1.28}\n",
      "{'loss': 0.8666, 'grad_norm': 0.3676081895828247, 'learning_rate': 7.232323232323233e-05, 'epoch': 1.28}\n",
      "{'loss': 0.8611, 'grad_norm': 0.3088872730731964, 'learning_rate': 7.191919191919192e-05, 'epoch': 1.29}\n",
      "{'loss': 0.6427, 'grad_norm': 0.26217418909072876, 'learning_rate': 7.151515151515152e-05, 'epoch': 1.29}\n",
      "{'loss': 0.7778, 'grad_norm': 0.3015446364879608, 'learning_rate': 7.111111111111112e-05, 'epoch': 1.3}\n",
      "{'loss': 0.9054, 'grad_norm': 0.31395816802978516, 'learning_rate': 7.07070707070707e-05, 'epoch': 1.3}\n",
      "{'loss': 0.9292, 'grad_norm': 0.36195987462997437, 'learning_rate': 7.03030303030303e-05, 'epoch': 1.3}\n",
      "{'loss': 0.7498, 'grad_norm': 0.30577296018600464, 'learning_rate': 6.98989898989899e-05, 'epoch': 1.31}\n",
      "{'loss': 0.8267, 'grad_norm': 0.34873300790786743, 'learning_rate': 6.94949494949495e-05, 'epoch': 1.31}\n",
      "{'loss': 0.7601, 'grad_norm': 0.3017405569553375, 'learning_rate': 6.90909090909091e-05, 'epoch': 1.32}\n",
      "{'loss': 0.7833, 'grad_norm': 0.3262907862663269, 'learning_rate': 6.86868686868687e-05, 'epoch': 1.32}\n",
      "{'loss': 0.786, 'grad_norm': 0.31311509013175964, 'learning_rate': 6.828282828282828e-05, 'epoch': 1.32}\n",
      "{'loss': 0.9041, 'grad_norm': 0.35306382179260254, 'learning_rate': 6.787878787878789e-05, 'epoch': 1.33}\n",
      "{'loss': 0.9125, 'grad_norm': 0.3247840106487274, 'learning_rate': 6.747474747474747e-05, 'epoch': 1.33}\n",
      "{'loss': 1.0317, 'grad_norm': 0.31804633140563965, 'learning_rate': 6.707070707070707e-05, 'epoch': 1.34}\n",
      "{'loss': 0.7141, 'grad_norm': 0.290848046541214, 'learning_rate': 6.666666666666667e-05, 'epoch': 1.34}\n",
      "{'loss': 0.9828, 'grad_norm': 0.3418886065483093, 'learning_rate': 6.626262626262627e-05, 'epoch': 1.34}\n",
      "{'loss': 0.8956, 'grad_norm': 0.3346678912639618, 'learning_rate': 6.585858585858587e-05, 'epoch': 1.35}\n",
      "{'loss': 0.7891, 'grad_norm': 0.3053100109100342, 'learning_rate': 6.545454545454546e-05, 'epoch': 1.35}\n",
      "{'loss': 0.73, 'grad_norm': 0.3475263714790344, 'learning_rate': 6.505050505050505e-05, 'epoch': 1.36}\n",
      "{'loss': 1.0826, 'grad_norm': 0.32898426055908203, 'learning_rate': 6.464646464646466e-05, 'epoch': 1.36}\n",
      "{'loss': 0.7504, 'grad_norm': 0.3085375726222992, 'learning_rate': 6.424242424242424e-05, 'epoch': 1.36}\n",
      "{'loss': 0.9156, 'grad_norm': 0.3133639693260193, 'learning_rate': 6.383838383838384e-05, 'epoch': 1.37}\n",
      "{'loss': 0.8717, 'grad_norm': 0.366336852312088, 'learning_rate': 6.343434343434344e-05, 'epoch': 1.37}\n",
      "{'loss': 0.6727, 'grad_norm': 0.28312021493911743, 'learning_rate': 6.303030303030302e-05, 'epoch': 1.38}\n",
      "{'loss': 0.8202, 'grad_norm': 0.3888266086578369, 'learning_rate': 6.262626262626264e-05, 'epoch': 1.38}\n",
      "{'loss': 0.7722, 'grad_norm': 0.314799964427948, 'learning_rate': 6.222222222222222e-05, 'epoch': 1.38}\n",
      "{'loss': 0.7891, 'grad_norm': 0.2742302715778351, 'learning_rate': 6.181818181818182e-05, 'epoch': 1.39}\n",
      "{'loss': 0.8285, 'grad_norm': 0.37357425689697266, 'learning_rate': 6.141414141414142e-05, 'epoch': 1.39}\n",
      "{'loss': 0.8737, 'grad_norm': 0.31235799193382263, 'learning_rate': 6.101010101010102e-05, 'epoch': 1.4}\n",
      "{'loss': 0.6502, 'grad_norm': 0.29861530661582947, 'learning_rate': 6.060606060606061e-05, 'epoch': 1.4}\n",
      "{'loss': 0.8069, 'grad_norm': 0.29782578349113464, 'learning_rate': 6.02020202020202e-05, 'epoch': 1.4}\n",
      "{'loss': 0.7915, 'grad_norm': 0.404315322637558, 'learning_rate': 5.97979797979798e-05, 'epoch': 1.41}\n",
      "{'loss': 0.743, 'grad_norm': 0.3989255726337433, 'learning_rate': 5.93939393939394e-05, 'epoch': 1.41}\n",
      "{'loss': 0.7683, 'grad_norm': 0.29155150055885315, 'learning_rate': 5.8989898989898996e-05, 'epoch': 1.42}\n",
      "{'loss': 0.7739, 'grad_norm': 0.36716732382774353, 'learning_rate': 5.858585858585859e-05, 'epoch': 1.42}\n",
      "{'loss': 0.8052, 'grad_norm': 0.3131522834300995, 'learning_rate': 5.818181818181818e-05, 'epoch': 1.42}\n",
      "{'loss': 0.8015, 'grad_norm': 0.3179178833961487, 'learning_rate': 5.7777777777777776e-05, 'epoch': 1.43}\n",
      "{'loss': 0.6954, 'grad_norm': 0.3189547657966614, 'learning_rate': 5.737373737373738e-05, 'epoch': 1.43}\n",
      "{'loss': 0.7781, 'grad_norm': 0.3353573679924011, 'learning_rate': 5.696969696969697e-05, 'epoch': 1.44}\n",
      "{'loss': 0.8168, 'grad_norm': 0.36955225467681885, 'learning_rate': 5.6565656565656563e-05, 'epoch': 1.44}\n",
      "{'loss': 0.8143, 'grad_norm': 0.32201001048088074, 'learning_rate': 5.616161616161616e-05, 'epoch': 1.44}\n",
      "{'loss': 0.833, 'grad_norm': 0.3435721695423126, 'learning_rate': 5.5757575757575766e-05, 'epoch': 1.45}\n",
      "{'loss': 0.8973, 'grad_norm': 0.328643798828125, 'learning_rate': 5.535353535353536e-05, 'epoch': 1.45}\n",
      "{'loss': 0.7329, 'grad_norm': 0.3215216100215912, 'learning_rate': 5.494949494949495e-05, 'epoch': 1.46}\n",
      "{'loss': 0.9551, 'grad_norm': 0.3296832740306854, 'learning_rate': 5.4545454545454546e-05, 'epoch': 1.46}\n",
      "{'loss': 0.9442, 'grad_norm': 0.31963953375816345, 'learning_rate': 5.414141414141415e-05, 'epoch': 1.46}\n",
      "{'loss': 0.8572, 'grad_norm': 0.35184234380722046, 'learning_rate': 5.373737373737374e-05, 'epoch': 1.47}\n",
      "{'loss': 0.8872, 'grad_norm': 0.3372303545475006, 'learning_rate': 5.333333333333333e-05, 'epoch': 1.47}\n",
      "{'loss': 0.88, 'grad_norm': 0.35814258456230164, 'learning_rate': 5.292929292929293e-05, 'epoch': 1.48}\n",
      "{'loss': 0.7666, 'grad_norm': 0.3537919819355011, 'learning_rate': 5.2525252525252536e-05, 'epoch': 1.48}\n",
      "{'loss': 0.9083, 'grad_norm': 0.326038122177124, 'learning_rate': 5.212121212121213e-05, 'epoch': 1.48}\n",
      "{'loss': 0.7246, 'grad_norm': 0.3379036784172058, 'learning_rate': 5.171717171717172e-05, 'epoch': 1.49}\n",
      "{'loss': 0.9734, 'grad_norm': 0.37564191222190857, 'learning_rate': 5.1313131313131316e-05, 'epoch': 1.49}\n",
      "{'loss': 0.8659, 'grad_norm': 0.313924640417099, 'learning_rate': 5.090909090909091e-05, 'epoch': 1.5}\n",
      "{'loss': 0.928, 'grad_norm': 0.3749498426914215, 'learning_rate': 5.050505050505051e-05, 'epoch': 1.5}\n",
      "{'loss': 1.0221, 'grad_norm': 0.34992504119873047, 'learning_rate': 5.01010101010101e-05, 'epoch': 1.5}\n",
      "{'loss': 0.7762, 'grad_norm': 0.30944541096687317, 'learning_rate': 4.9696969696969694e-05, 'epoch': 1.51}\n",
      "{'loss': 0.8385, 'grad_norm': 0.31042662262916565, 'learning_rate': 4.92929292929293e-05, 'epoch': 1.51}\n",
      "{'loss': 0.8996, 'grad_norm': 0.33743801712989807, 'learning_rate': 4.888888888888889e-05, 'epoch': 1.52}\n",
      "{'loss': 0.8601, 'grad_norm': 0.36940985918045044, 'learning_rate': 4.848484848484849e-05, 'epoch': 1.52}\n",
      "{'loss': 0.8825, 'grad_norm': 0.33269113302230835, 'learning_rate': 4.808080808080808e-05, 'epoch': 1.52}\n",
      "{'loss': 0.8032, 'grad_norm': 0.314306378364563, 'learning_rate': 4.7676767676767684e-05, 'epoch': 1.53}\n",
      "{'loss': 0.8803, 'grad_norm': 0.3515799641609192, 'learning_rate': 4.7272727272727275e-05, 'epoch': 1.53}\n",
      "{'loss': 0.8755, 'grad_norm': 0.379861980676651, 'learning_rate': 4.686868686868687e-05, 'epoch': 1.54}\n",
      "{'loss': 0.8226, 'grad_norm': 0.31232038140296936, 'learning_rate': 4.6464646464646464e-05, 'epoch': 1.54}\n",
      "{'loss': 0.7775, 'grad_norm': 0.3627985417842865, 'learning_rate': 4.606060606060607e-05, 'epoch': 1.54}\n",
      "{'loss': 0.8148, 'grad_norm': 0.34055790305137634, 'learning_rate': 4.565656565656566e-05, 'epoch': 1.55}\n",
      "{'loss': 0.6703, 'grad_norm': 0.2820691466331482, 'learning_rate': 4.525252525252526e-05, 'epoch': 1.55}\n",
      "{'loss': 0.8888, 'grad_norm': 0.35740286111831665, 'learning_rate': 4.484848484848485e-05, 'epoch': 1.56}\n",
      "{'loss': 0.9137, 'grad_norm': 0.31715381145477295, 'learning_rate': 4.4444444444444447e-05, 'epoch': 1.56}\n",
      "{'loss': 0.7491, 'grad_norm': 0.2964627146720886, 'learning_rate': 4.4040404040404044e-05, 'epoch': 1.56}\n",
      "{'loss': 0.7766, 'grad_norm': 0.3485667407512665, 'learning_rate': 4.3636363636363636e-05, 'epoch': 1.57}\n",
      "{'loss': 0.9267, 'grad_norm': 0.32862043380737305, 'learning_rate': 4.3232323232323234e-05, 'epoch': 1.57}\n",
      "{'loss': 0.7282, 'grad_norm': 0.36867988109588623, 'learning_rate': 4.282828282828283e-05, 'epoch': 1.58}\n",
      "{'loss': 0.7995, 'grad_norm': 0.32250913977622986, 'learning_rate': 4.242424242424243e-05, 'epoch': 1.58}\n",
      "{'loss': 0.9467, 'grad_norm': 0.3786410987377167, 'learning_rate': 4.202020202020202e-05, 'epoch': 1.58}\n",
      "{'loss': 0.8692, 'grad_norm': 0.3475106656551361, 'learning_rate': 4.161616161616162e-05, 'epoch': 1.59}\n",
      "{'loss': 0.8519, 'grad_norm': 0.36547771096229553, 'learning_rate': 4.1212121212121216e-05, 'epoch': 1.59}\n",
      "{'loss': 0.7274, 'grad_norm': 0.37555697560310364, 'learning_rate': 4.0808080808080814e-05, 'epoch': 1.6}\n",
      "{'loss': 0.7922, 'grad_norm': 0.3365446925163269, 'learning_rate': 4.0404040404040405e-05, 'epoch': 1.6}\n",
      "{'loss': 0.7923, 'grad_norm': 0.38173359632492065, 'learning_rate': 4e-05, 'epoch': 1.6}\n",
      "{'loss': 0.889, 'grad_norm': 0.36445537209510803, 'learning_rate': 3.9595959595959594e-05, 'epoch': 1.61}\n",
      "{'loss': 0.892, 'grad_norm': 0.30570828914642334, 'learning_rate': 3.91919191919192e-05, 'epoch': 1.61}\n",
      "{'loss': 0.7963, 'grad_norm': 0.3516271412372589, 'learning_rate': 3.878787878787879e-05, 'epoch': 1.62}\n",
      "{'loss': 0.8586, 'grad_norm': 0.3528035879135132, 'learning_rate': 3.838383838383838e-05, 'epoch': 1.62}\n",
      "{'loss': 0.8853, 'grad_norm': 0.33315953612327576, 'learning_rate': 3.797979797979798e-05, 'epoch': 1.62}\n",
      "{'loss': 0.838, 'grad_norm': 0.344353049993515, 'learning_rate': 3.757575757575758e-05, 'epoch': 1.63}\n",
      "{'loss': 0.6793, 'grad_norm': 0.29186153411865234, 'learning_rate': 3.7171717171717175e-05, 'epoch': 1.63}\n",
      "{'loss': 0.9797, 'grad_norm': 0.38582149147987366, 'learning_rate': 3.6767676767676766e-05, 'epoch': 1.64}\n",
      "{'loss': 0.8532, 'grad_norm': 0.3217337131500244, 'learning_rate': 3.6363636363636364e-05, 'epoch': 1.64}\n",
      "{'loss': 0.7568, 'grad_norm': 0.3210465610027313, 'learning_rate': 3.595959595959596e-05, 'epoch': 1.64}\n",
      "{'loss': 0.812, 'grad_norm': 0.4036366045475006, 'learning_rate': 3.555555555555556e-05, 'epoch': 1.65}\n",
      "{'loss': 0.7502, 'grad_norm': 0.3875076174736023, 'learning_rate': 3.515151515151515e-05, 'epoch': 1.65}\n",
      "{'loss': 0.8237, 'grad_norm': 0.3474946618080139, 'learning_rate': 3.474747474747475e-05, 'epoch': 1.66}\n",
      "{'loss': 0.7922, 'grad_norm': 0.3340957760810852, 'learning_rate': 3.434343434343435e-05, 'epoch': 1.66}\n",
      "{'loss': 0.7044, 'grad_norm': 0.3348270654678345, 'learning_rate': 3.3939393939393945e-05, 'epoch': 1.66}\n",
      "{'loss': 0.7758, 'grad_norm': 0.32160839438438416, 'learning_rate': 3.3535353535353536e-05, 'epoch': 1.67}\n",
      "{'loss': 0.6321, 'grad_norm': 0.3133517801761627, 'learning_rate': 3.3131313131313134e-05, 'epoch': 1.67}\n",
      "{'loss': 0.623, 'grad_norm': 0.31937670707702637, 'learning_rate': 3.272727272727273e-05, 'epoch': 1.68}\n",
      "{'loss': 0.8582, 'grad_norm': 0.3250786066055298, 'learning_rate': 3.232323232323233e-05, 'epoch': 1.68}\n",
      "{'loss': 0.7724, 'grad_norm': 0.3240671753883362, 'learning_rate': 3.191919191919192e-05, 'epoch': 1.68}\n",
      "{'loss': 0.8753, 'grad_norm': 0.3603638708591461, 'learning_rate': 3.151515151515151e-05, 'epoch': 1.69}\n",
      "{'loss': 0.8613, 'grad_norm': 0.3307710886001587, 'learning_rate': 3.111111111111111e-05, 'epoch': 1.69}\n",
      "{'loss': 0.7649, 'grad_norm': 0.3313707411289215, 'learning_rate': 3.070707070707071e-05, 'epoch': 1.7}\n",
      "{'loss': 0.7541, 'grad_norm': 0.3101074993610382, 'learning_rate': 3.0303030303030306e-05, 'epoch': 1.7}\n",
      "{'loss': 0.7967, 'grad_norm': 0.35271620750427246, 'learning_rate': 2.98989898989899e-05, 'epoch': 1.7}\n",
      "{'loss': 0.7929, 'grad_norm': 0.3513927757740021, 'learning_rate': 2.9494949494949498e-05, 'epoch': 1.71}\n",
      "{'loss': 0.768, 'grad_norm': 0.3563811480998993, 'learning_rate': 2.909090909090909e-05, 'epoch': 1.71}\n",
      "{'loss': 0.7618, 'grad_norm': 0.3250695466995239, 'learning_rate': 2.868686868686869e-05, 'epoch': 1.72}\n",
      "{'loss': 0.7782, 'grad_norm': 0.3144267201423645, 'learning_rate': 2.8282828282828282e-05, 'epoch': 1.72}\n",
      "{'loss': 0.9657, 'grad_norm': 0.3442542850971222, 'learning_rate': 2.7878787878787883e-05, 'epoch': 1.72}\n",
      "{'loss': 0.7194, 'grad_norm': 0.3086300492286682, 'learning_rate': 2.7474747474747474e-05, 'epoch': 1.73}\n",
      "{'loss': 0.9478, 'grad_norm': 0.3375449776649475, 'learning_rate': 2.7070707070707075e-05, 'epoch': 1.73}\n",
      "{'loss': 0.7104, 'grad_norm': 0.31494230031967163, 'learning_rate': 2.6666666666666667e-05, 'epoch': 1.74}\n",
      "{'loss': 0.973, 'grad_norm': 0.3139187693595886, 'learning_rate': 2.6262626262626268e-05, 'epoch': 1.74}\n",
      "{'loss': 0.89, 'grad_norm': 0.4364747703075409, 'learning_rate': 2.585858585858586e-05, 'epoch': 1.74}\n",
      "{'loss': 0.7799, 'grad_norm': 0.35672491788864136, 'learning_rate': 2.5454545454545454e-05, 'epoch': 1.75}\n",
      "{'loss': 0.5354, 'grad_norm': 0.280555784702301, 'learning_rate': 2.505050505050505e-05, 'epoch': 1.75}\n",
      "{'loss': 0.9785, 'grad_norm': 0.34918931126594543, 'learning_rate': 2.464646464646465e-05, 'epoch': 1.76}\n",
      "{'loss': 0.7802, 'grad_norm': 0.315303236246109, 'learning_rate': 2.4242424242424244e-05, 'epoch': 1.76}\n",
      "{'loss': 0.7601, 'grad_norm': 0.31965142488479614, 'learning_rate': 2.3838383838383842e-05, 'epoch': 1.76}\n",
      "{'loss': 0.8898, 'grad_norm': 0.3270593583583832, 'learning_rate': 2.3434343434343436e-05, 'epoch': 1.77}\n",
      "{'loss': 0.8006, 'grad_norm': 0.3475213050842285, 'learning_rate': 2.3030303030303034e-05, 'epoch': 1.77}\n",
      "{'loss': 0.6781, 'grad_norm': 0.3177393078804016, 'learning_rate': 2.262626262626263e-05, 'epoch': 1.78}\n",
      "{'loss': 0.7319, 'grad_norm': 0.31353986263275146, 'learning_rate': 2.2222222222222223e-05, 'epoch': 1.78}\n",
      "{'loss': 0.7296, 'grad_norm': 0.33736586570739746, 'learning_rate': 2.1818181818181818e-05, 'epoch': 1.78}\n",
      "{'loss': 0.9304, 'grad_norm': 0.2925814688205719, 'learning_rate': 2.1414141414141416e-05, 'epoch': 1.79}\n",
      "{'loss': 0.8208, 'grad_norm': 0.38850632309913635, 'learning_rate': 2.101010101010101e-05, 'epoch': 1.79}\n",
      "{'loss': 0.7835, 'grad_norm': 0.32219845056533813, 'learning_rate': 2.0606060606060608e-05, 'epoch': 1.8}\n",
      "{'loss': 0.7213, 'grad_norm': 0.3084544241428375, 'learning_rate': 2.0202020202020203e-05, 'epoch': 1.8}\n",
      "{'loss': 0.8953, 'grad_norm': 0.3256559669971466, 'learning_rate': 1.9797979797979797e-05, 'epoch': 1.8}\n",
      "{'loss': 0.8654, 'grad_norm': 0.37212812900543213, 'learning_rate': 1.9393939393939395e-05, 'epoch': 1.81}\n",
      "{'loss': 0.6108, 'grad_norm': 0.3141801357269287, 'learning_rate': 1.898989898989899e-05, 'epoch': 1.81}\n",
      "{'loss': 0.7767, 'grad_norm': 0.3118641674518585, 'learning_rate': 1.8585858585858588e-05, 'epoch': 1.82}\n",
      "{'loss': 0.735, 'grad_norm': 0.3265353739261627, 'learning_rate': 1.8181818181818182e-05, 'epoch': 1.82}\n",
      "{'loss': 0.8212, 'grad_norm': 0.3728715479373932, 'learning_rate': 1.777777777777778e-05, 'epoch': 1.82}\n",
      "{'loss': 0.8393, 'grad_norm': 0.31131282448768616, 'learning_rate': 1.7373737373737375e-05, 'epoch': 1.83}\n",
      "{'loss': 0.9745, 'grad_norm': 0.3349020183086395, 'learning_rate': 1.6969696969696972e-05, 'epoch': 1.83}\n",
      "{'loss': 0.8871, 'grad_norm': 0.3206871747970581, 'learning_rate': 1.6565656565656567e-05, 'epoch': 1.84}\n",
      "{'loss': 0.8733, 'grad_norm': 0.3623243570327759, 'learning_rate': 1.6161616161616165e-05, 'epoch': 1.84}\n",
      "{'loss': 0.81, 'grad_norm': 0.3027816712856293, 'learning_rate': 1.5757575757575756e-05, 'epoch': 1.84}\n",
      "{'loss': 0.8724, 'grad_norm': 0.3269582986831665, 'learning_rate': 1.5353535353535354e-05, 'epoch': 1.85}\n",
      "{'loss': 0.6493, 'grad_norm': 0.3466190993785858, 'learning_rate': 1.494949494949495e-05, 'epoch': 1.85}\n",
      "{'loss': 0.7962, 'grad_norm': 0.33482104539871216, 'learning_rate': 1.4545454545454545e-05, 'epoch': 1.86}\n",
      "{'loss': 0.8713, 'grad_norm': 0.32917895913124084, 'learning_rate': 1.4141414141414141e-05, 'epoch': 1.86}\n",
      "{'loss': 0.9341, 'grad_norm': 0.4021061956882477, 'learning_rate': 1.3737373737373737e-05, 'epoch': 1.86}\n",
      "{'loss': 0.7759, 'grad_norm': 0.31125813722610474, 'learning_rate': 1.3333333333333333e-05, 'epoch': 1.87}\n",
      "{'loss': 0.813, 'grad_norm': 0.37825143337249756, 'learning_rate': 1.292929292929293e-05, 'epoch': 1.87}\n",
      "{'loss': 0.6795, 'grad_norm': 0.3139140009880066, 'learning_rate': 1.2525252525252526e-05, 'epoch': 1.88}\n",
      "{'loss': 0.781, 'grad_norm': 0.3154447078704834, 'learning_rate': 1.2121212121212122e-05, 'epoch': 1.88}\n",
      "{'loss': 0.9289, 'grad_norm': 0.34360623359680176, 'learning_rate': 1.1717171717171718e-05, 'epoch': 1.88}\n",
      "{'loss': 0.7677, 'grad_norm': 0.3288117051124573, 'learning_rate': 1.1313131313131314e-05, 'epoch': 1.89}\n",
      "{'loss': 0.7052, 'grad_norm': 0.3083788752555847, 'learning_rate': 1.0909090909090909e-05, 'epoch': 1.89}\n",
      "{'loss': 0.9289, 'grad_norm': 0.4001109302043915, 'learning_rate': 1.0505050505050505e-05, 'epoch': 1.9}\n",
      "{'loss': 0.7716, 'grad_norm': 0.2993679642677307, 'learning_rate': 1.0101010101010101e-05, 'epoch': 1.9}\n",
      "{'loss': 0.7408, 'grad_norm': 0.3605692684650421, 'learning_rate': 9.696969696969698e-06, 'epoch': 1.9}\n",
      "{'loss': 0.9213, 'grad_norm': 0.36233940720558167, 'learning_rate': 9.292929292929294e-06, 'epoch': 1.91}\n",
      "{'loss': 0.7523, 'grad_norm': 0.311275839805603, 'learning_rate': 8.88888888888889e-06, 'epoch': 1.91}\n",
      "{'loss': 0.752, 'grad_norm': 0.3760503828525543, 'learning_rate': 8.484848484848486e-06, 'epoch': 1.92}\n",
      "{'loss': 0.8099, 'grad_norm': 0.3256337344646454, 'learning_rate': 8.080808080808082e-06, 'epoch': 1.92}\n",
      "{'loss': 0.6743, 'grad_norm': 0.3020692765712738, 'learning_rate': 7.676767676767677e-06, 'epoch': 1.92}\n",
      "{'loss': 0.8698, 'grad_norm': 0.3441801369190216, 'learning_rate': 7.272727272727272e-06, 'epoch': 1.93}\n",
      "{'loss': 0.7737, 'grad_norm': 0.3123166561126709, 'learning_rate': 6.8686868686868685e-06, 'epoch': 1.93}\n",
      "{'loss': 0.7481, 'grad_norm': 0.3484208583831787, 'learning_rate': 6.464646464646465e-06, 'epoch': 1.94}\n",
      "{'loss': 0.953, 'grad_norm': 0.3337022364139557, 'learning_rate': 6.060606060606061e-06, 'epoch': 1.94}\n",
      "{'loss': 0.6886, 'grad_norm': 0.30613893270492554, 'learning_rate': 5.656565656565657e-06, 'epoch': 1.94}\n",
      "{'loss': 0.6925, 'grad_norm': 0.29824042320251465, 'learning_rate': 5.2525252525252526e-06, 'epoch': 1.95}\n",
      "{'loss': 0.8181, 'grad_norm': 0.3531474173069, 'learning_rate': 4.848484848484849e-06, 'epoch': 1.95}\n",
      "{'loss': 0.7307, 'grad_norm': 0.3414625823497772, 'learning_rate': 4.444444444444445e-06, 'epoch': 1.96}\n",
      "{'loss': 0.7037, 'grad_norm': 0.3329657018184662, 'learning_rate': 4.040404040404041e-06, 'epoch': 1.96}\n",
      "{'loss': 0.7522, 'grad_norm': 0.34174713492393494, 'learning_rate': 3.636363636363636e-06, 'epoch': 1.96}\n",
      "{'loss': 0.852, 'grad_norm': 0.3370078504085541, 'learning_rate': 3.2323232323232324e-06, 'epoch': 1.97}\n",
      "{'loss': 0.7418, 'grad_norm': 0.3652641773223877, 'learning_rate': 2.8282828282828286e-06, 'epoch': 1.97}\n",
      "{'loss': 0.7784, 'grad_norm': 0.32237109541893005, 'learning_rate': 2.4242424242424244e-06, 'epoch': 1.98}\n",
      "{'loss': 0.7257, 'grad_norm': 0.33904144167900085, 'learning_rate': 2.0202020202020206e-06, 'epoch': 1.98}\n",
      "{'loss': 0.9428, 'grad_norm': 0.3342122733592987, 'learning_rate': 1.6161616161616162e-06, 'epoch': 1.98}\n",
      "{'loss': 0.8273, 'grad_norm': 0.36215025186538696, 'learning_rate': 1.2121212121212122e-06, 'epoch': 1.99}\n",
      "{'loss': 0.9456, 'grad_norm': 0.3608078360557556, 'learning_rate': 8.080808080808081e-07, 'epoch': 1.99}\n",
      "{'loss': 0.8123, 'grad_norm': 0.3924775719642639, 'learning_rate': 4.0404040404040405e-07, 'epoch': 2.0}\n",
      "{'loss': 0.8561, 'grad_norm': 0.3080828785896301, 'learning_rate': 0.0, 'epoch': 2.0}\n",
      "{'train_runtime': 733.9232, 'train_samples_per_second': 5.45, 'train_steps_per_second': 0.681, 'train_loss': 0.9092961210012436, 'epoch': 2.0}\n"
     ]
    }
   ],
   "source": [
    "trainer_stats = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system\n",
      "You are a helpful assistant.<|im_end|>\n",
      "<|im_start|>user\n",
      "Can you tell me about triangles...<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Certainly! Triangles are fundamental geometric shapes and play crucial roles in various fields such as architecture, engineering, physics, and computer science.\n",
      "\n",
      "### Basic Types of Triangles\n",
      "\n",
      "1. **Equilateral Triangle**: All three sides have the same length.\n",
      "2. **Isosceles Triangle**: Two sides are equal in length; the third side is different from these two.\n",
      "3. **Scalene Triangle**: No sides are equal in length.\n",
      "\n",
      "### Classification Based on Angles\n",
      "\n",
      "- **Acute-Angled Triangle**: All interior angles are less than 90 degrees (right angle).\n",
      "- **Right-Angled Triangle**: One angle measures exactly 90 degrees (a right angle). The side opposite this angle is called the hypotenuse, which is always the longest side.\n",
      "- **Obtuse-Angled Triangle**: One interior angle is greater than 90 degrees but less than 180 degrees.\n",
      "\n",
      "### Properties of Triangles\n",
      "\n",
      "- **Sum of Interior Angles**: In any triangle, the sum of all three internal angles equals 180 degrees.\n",
      "- **Pythagorean Theorem** (for right-angled triangles): If \\(a^2 + b^2 = c^2\\), where \\(c\\) represents the hypotenuse, then \\((side_1)^2 + (side_2)^2 = (hypotenuse)^2\\).\n",
      "\n",
      "### Special Cases\n",
      "\n",
      "- **3-Sided Polygon**: A triangle has no curves or bends, making it an open figure with straight edges.\n",
      "- **Triangle Inequality Theorem**: For any triangle, the sum of the lengths of any two sides must be greater than the length of the remaining side.\n",
      "\n",
      "### Applications of Triangles\n",
      "\n",
      "- **Structural Engineering**: Triangles provide strength because they can distribute forces evenly across their structure.\n",
      "- **Navigation and Mapping**: Triangles help calculate distances between points when using triangulation methods.\n",
      "- **Computer Graphics & Animation**: Triangles form the basic building blocks for polygon meshes used extensively in 3D modeling and rendering software.\n",
      "\n",
      "Understanding triangles is essential not only mathematically but also practically across many disciplines due to their inherent properties that make them versatile tools for solving problems involving geometry and mechanics.<|im_end|>\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"<|im_start|>system\n",
    "You are a helpful assistant.<|im_end|>\n",
    "<|im_start|>user\n",
    "Can you tell me about triangles...<|im_end|>\n",
    "<|im_start|>assistant\n",
    "\"\"\"\n",
    "\n",
    "FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
    "inputs=tokenizer([prompt], return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "outputs=model.generate(**inputs, max_new_tokens=512, use_cache=True)\n",
    "print(tokenizer.batch_decode(outputs)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: You're not saving a tokenizer as well?\n",
      "You can do it separately via `tokenizer.save_pretrained(...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Merging 4bit and LoRA weights to 16bit...\n",
      "Unsloth: Will use up to 14.05 out of 31.11 RAM for saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [00:00<00:00, 186.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unsloth: Saving model... This might take 5 minutes for Llama-7b...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "model.save_pretrained_merged(\"output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
