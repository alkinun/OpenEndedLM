{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "==((====))==  Unsloth 2024.10.7: Fast Qwen2 patching. Transformers = 4.46.1.\n",
      "   \\\\   /|    GPU: NVIDIA GeForce RTX 3090. Max memory: 23.668 GB. Platform = Linux.\n",
      "O^O/ \\_/ \\    Pytorch: 2.4.0+cu121. CUDA = 8.6. CUDA Toolkit = 12.1.\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.27.post2. FA2 = True]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:204: SyntaxWarning: invalid escape sequence '\\ '\n",
      "<string>:205: SyntaxWarning: invalid escape sequence '\\_'\n",
      "<string>:206: SyntaxWarning: invalid escape sequence '\\ '\n",
      "<string>:204: SyntaxWarning: invalid escape sequence '\\ '\n",
      "<string>:205: SyntaxWarning: invalid escape sequence '\\_'\n",
      "<string>:206: SyntaxWarning: invalid escape sequence '\\ '\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "\n",
    "max_seq_length = 4096 # Choose any! We auto support RoPE Scaling internally!\n",
    "dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
    "load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.\n",
    "\n",
    "model, tokenizer=FastLanguageModel.from_pretrained(\n",
    "    model_name=\"Qwen/Qwen2.5-1.5B-Instruct\",\n",
    "    max_seq_length=max_seq_length,\n",
    "    dtype=dtype,\n",
    "    load_in_4bit=load_in_4bit,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2024.10.7 patched 28 layers with 0 QKV layers, 28 O layers and 28 MLP layers.\n"
     ]
    }
   ],
   "source": [
    "model=FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r=64, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                    \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
    "    lora_alpha=64,\n",
    "    lora_dropout=0, # Currently only supports dropout=0\n",
    "    bias=\"none\",    # Currently only supports bias=\"none\"\n",
    "    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n",
    "    use_gradient_checkpointing=\"unsloth\", # True or \"unsloth\" for very long context\n",
    "    random_state=3407,\n",
    "    use_rslora=False,  # We support rank stabilized LoRA\n",
    "    loftq_config=None, # And LoftQ\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bb8b35782824232a3031c3adc6d06f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/311 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14580a615c7c419583839175ea022dc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/715k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5da3667bd0741c4926dd7b191aff3e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf64825d6715408f83f1e55f2c8177df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt_template = \"\"\"<|im_start|>system\n",
    "You are a helpful assistant.<|im_end|>\n",
    "<|im_start|>user\n",
    "{}<|im_end|>\n",
    "<|im_start|>assistant\n",
    "{}<|im_end|>\"\"\"\n",
    "\n",
    "EOS_TOKEN = tokenizer.eos_token # Must add EOS_TOKEN\n",
    "\n",
    "def format_prompt(examples):\n",
    "    prompts   = examples[\"prompt\"]\n",
    "    responses = examples[\"response\"]\n",
    "    texts = []\n",
    "    for prompt, response in zip(prompts, responses):\n",
    "        # Must add EOS_TOKEN, otherwise your generation will go on forever!\n",
    "        text = prompt_template.format(prompt, response)\n",
    "        texts.append(text)\n",
    "    return {\"text\": texts}\n",
    "\n",
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"OpenEndedLM/OpenEnded-v0.1\")[\"train\"]\n",
    "dataset = dataset.map(format_prompt, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system\n",
      "You are a helpful assistant.<|im_end|>\n",
      "<|im_start|>user\n",
      "How does mental health contribute to overall wellbeing and how can it be improved?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Mental health contributes significantly to overall wellbeing in numerous ways:\n",
      "\n",
      "1. **Coping and Resilience:** Strong mental health enables individuals to effectively navigate challenges, adapt to changes, and maintain emotional stability. This resilience helps them cope with stressors, job problems, health issues, relationships, and life events.\n",
      "\n",
      "2. **Behavioral Health:** Mental health supports healthy behaviors such as good nutrition, physical activity, and adequate sleep. These are essential for overall health and wellness.\n",
      "\n",
      "3. **Social Functioning:** It fosters good relationships, enhances social interaction, and improves collaboration in a team setting. Happy and healthy individuals tend to reciprocate these qualities, which benefits their social connections.\n",
      "\n",
      "4. **Personal Development:** Mental health supports personal growth. It provides an opportunity to learn, improve, and set goals that could lead to improved academic, professional, and social outcomes.\n",
      "\n",
      "5. **Absence of Mental Illness:** Having good mental health means not being troubled by mental illness. Disruptions to mental health disrupt the functional integrity of the brain.\n",
      "\n",
      "Improving mental health involves addressing various issues:\n",
      "\n",
      "1. **Self-care:** Engaging in activities that have a positive impact on mental health, such as exercise, healthy eating, and sufficient sleep.\n",
      "\n",
      "2. **Balanced Diet:** Maintaining consistency in your diet and adjusting accordingly based on your individual needs.\n",
      "\n",
      "3. **Regular Physical Activity:** Incorporating any form of exercise into your routine ensures a healthy physical and psychological state.\n",
      "\n",
      "4. **Proper Sleep:** Prioritizing restful, uninterrupted sleep enhances mental health and well-being.\n",
      "\n",
      "5. **Social Support:** Connecting with friends and family, maintaining strong social bonds, and being able to seek support from professionals when needed.\n",
      "\n",
      "By prioritizing mental health and taking proactive steps to improve it, one can enhance their overall wellbeing and achieve holistic health and success.<|im_end|>\n"
     ]
    }
   ],
   "source": [
    "print(dataset[\"text\"][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b374fbeebb8496fb9f46abf7a3eb24a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=2):   0%|          | 0/600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from trl import SFTTrainer\n",
    "from transformers import TrainingArguments\n",
    "from unsloth import is_bfloat16_supported\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    train_dataset = dataset,\n",
    "    dataset_text_field = \"text\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    dataset_num_proc = 2,\n",
    "    packing = False, # Can make training 5x faster for short sequences.\n",
    "    args = TrainingArguments(\n",
    "        per_device_train_batch_size = 2,\n",
    "        gradient_accumulation_steps = 4,\n",
    "        warmup_steps = 5,\n",
    "\n",
    "        num_train_epochs = 2,\n",
    "        #max_steps = 60,\n",
    "\n",
    "        learning_rate = 2e-4,\n",
    "        fp16 = not is_bfloat16_supported(),\n",
    "        bf16 = is_bfloat16_supported(),\n",
    "        logging_steps = 1,\n",
    "        optim = \"adamw_8bit\",\n",
    "        weight_decay = 0.01,\n",
    "        lr_scheduler_type = \"linear\",\n",
    "        seed = 3407,\n",
    "        output_dir = \"outputs\",\n",
    "        report_to = \"none\", # Use this for WandB etc\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
      "   \\\\   /|    Num examples = 600 | Num Epochs = 2\n",
      "O^O/ \\_/ \\    Batch size per device = 2 | Gradient Accumulation steps = 4\n",
      "\\        /    Total batch size = 8 | Total steps = 150\n",
      " \"-____-\"     Number of trainable parameters = 73,859,072\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ac16b2c18b346ccb31cb838dab51332",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/150 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.6349, 'grad_norm': 0.5394589304924011, 'learning_rate': 4e-05, 'epoch': 0.01}\n",
      "{'loss': 1.0732, 'grad_norm': 0.4944881200790405, 'learning_rate': 8e-05, 'epoch': 0.03}\n",
      "{'loss': 1.312, 'grad_norm': 0.5473517179489136, 'learning_rate': 0.00012, 'epoch': 0.04}\n",
      "{'loss': 1.5588, 'grad_norm': 0.38827428221702576, 'learning_rate': 0.00016, 'epoch': 0.05}\n",
      "{'loss': 1.3074, 'grad_norm': 0.396592378616333, 'learning_rate': 0.0002, 'epoch': 0.07}\n",
      "{'loss': 1.6947, 'grad_norm': 0.32169005274772644, 'learning_rate': 0.00019862068965517243, 'epoch': 0.08}\n",
      "{'loss': 1.2959, 'grad_norm': 0.2792431712150574, 'learning_rate': 0.00019724137931034484, 'epoch': 0.09}\n",
      "{'loss': 1.3212, 'grad_norm': 0.36545509099960327, 'learning_rate': 0.00019586206896551723, 'epoch': 0.11}\n",
      "{'loss': 1.1028, 'grad_norm': 0.30583956837654114, 'learning_rate': 0.00019448275862068965, 'epoch': 0.12}\n",
      "{'loss': 1.0802, 'grad_norm': 0.33153149485588074, 'learning_rate': 0.0001931034482758621, 'epoch': 0.13}\n",
      "{'loss': 0.9743, 'grad_norm': 0.31950613856315613, 'learning_rate': 0.0001917241379310345, 'epoch': 0.15}\n",
      "{'loss': 1.0497, 'grad_norm': 0.31746190786361694, 'learning_rate': 0.0001903448275862069, 'epoch': 0.16}\n",
      "{'loss': 1.26, 'grad_norm': 0.29040369391441345, 'learning_rate': 0.00018896551724137932, 'epoch': 0.17}\n",
      "{'loss': 1.2917, 'grad_norm': 0.3594294488430023, 'learning_rate': 0.00018758620689655173, 'epoch': 0.19}\n",
      "{'loss': 1.0663, 'grad_norm': 0.34870609641075134, 'learning_rate': 0.00018620689655172415, 'epoch': 0.2}\n",
      "{'loss': 1.1925, 'grad_norm': 0.2878974974155426, 'learning_rate': 0.00018482758620689654, 'epoch': 0.21}\n",
      "{'loss': 1.1661, 'grad_norm': 0.2968774735927582, 'learning_rate': 0.00018344827586206896, 'epoch': 0.23}\n",
      "{'loss': 0.7601, 'grad_norm': 0.24162642657756805, 'learning_rate': 0.0001820689655172414, 'epoch': 0.24}\n",
      "{'loss': 1.4404, 'grad_norm': 0.31518980860710144, 'learning_rate': 0.00018068965517241382, 'epoch': 0.25}\n",
      "{'loss': 1.2398, 'grad_norm': 0.24713826179504395, 'learning_rate': 0.0001793103448275862, 'epoch': 0.27}\n",
      "{'loss': 1.3266, 'grad_norm': 0.3664088845252991, 'learning_rate': 0.00017793103448275862, 'epoch': 0.28}\n",
      "{'loss': 1.2289, 'grad_norm': 0.33796027302742004, 'learning_rate': 0.00017655172413793104, 'epoch': 0.29}\n",
      "{'loss': 1.5117, 'grad_norm': 0.29903310537338257, 'learning_rate': 0.00017517241379310346, 'epoch': 0.31}\n",
      "{'loss': 1.3519, 'grad_norm': 0.2589099705219269, 'learning_rate': 0.00017379310344827587, 'epoch': 0.32}\n",
      "{'loss': 1.6184, 'grad_norm': 0.2616786062717438, 'learning_rate': 0.00017241379310344826, 'epoch': 0.33}\n",
      "{'loss': 1.1356, 'grad_norm': 0.2670711576938629, 'learning_rate': 0.0001710344827586207, 'epoch': 0.35}\n",
      "{'loss': 0.6911, 'grad_norm': 0.34625503420829773, 'learning_rate': 0.00016965517241379312, 'epoch': 0.36}\n",
      "{'loss': 1.3234, 'grad_norm': 0.31233611702919006, 'learning_rate': 0.00016827586206896554, 'epoch': 0.37}\n",
      "{'loss': 1.5004, 'grad_norm': 0.34676191210746765, 'learning_rate': 0.00016689655172413793, 'epoch': 0.39}\n",
      "{'loss': 1.1098, 'grad_norm': 0.30696573853492737, 'learning_rate': 0.00016551724137931035, 'epoch': 0.4}\n",
      "{'loss': 0.8429, 'grad_norm': 0.26434534788131714, 'learning_rate': 0.00016413793103448276, 'epoch': 0.41}\n",
      "{'loss': 1.2589, 'grad_norm': 0.3086671531200409, 'learning_rate': 0.00016275862068965518, 'epoch': 0.43}\n",
      "{'loss': 1.3572, 'grad_norm': 0.31863486766815186, 'learning_rate': 0.0001613793103448276, 'epoch': 0.44}\n",
      "{'loss': 1.2123, 'grad_norm': 0.3085528314113617, 'learning_rate': 0.00016, 'epoch': 0.45}\n",
      "{'loss': 1.4906, 'grad_norm': 0.3128654956817627, 'learning_rate': 0.00015862068965517243, 'epoch': 0.47}\n",
      "{'loss': 1.4291, 'grad_norm': 0.32673177123069763, 'learning_rate': 0.00015724137931034485, 'epoch': 0.48}\n",
      "{'loss': 1.1226, 'grad_norm': 0.30186790227890015, 'learning_rate': 0.00015586206896551724, 'epoch': 0.49}\n",
      "{'loss': 1.1743, 'grad_norm': 0.3173505365848541, 'learning_rate': 0.00015448275862068965, 'epoch': 0.51}\n",
      "{'loss': 1.1206, 'grad_norm': 0.32083407044410706, 'learning_rate': 0.00015310344827586207, 'epoch': 0.52}\n",
      "{'loss': 1.2784, 'grad_norm': 0.2544136345386505, 'learning_rate': 0.00015172413793103449, 'epoch': 0.53}\n",
      "{'loss': 1.4428, 'grad_norm': 0.31014618277549744, 'learning_rate': 0.0001503448275862069, 'epoch': 0.55}\n",
      "{'loss': 1.3358, 'grad_norm': 0.2965472340583801, 'learning_rate': 0.00014896551724137932, 'epoch': 0.56}\n",
      "{'loss': 1.4673, 'grad_norm': 0.3610881268978119, 'learning_rate': 0.00014758620689655174, 'epoch': 0.57}\n",
      "{'loss': 1.2776, 'grad_norm': 0.2621484398841858, 'learning_rate': 0.00014620689655172415, 'epoch': 0.59}\n",
      "{'loss': 1.4027, 'grad_norm': 0.27682632207870483, 'learning_rate': 0.00014482758620689657, 'epoch': 0.6}\n",
      "{'loss': 1.3245, 'grad_norm': 0.2975136339664459, 'learning_rate': 0.00014344827586206896, 'epoch': 0.61}\n",
      "{'loss': 0.8873, 'grad_norm': 0.2237379401922226, 'learning_rate': 0.00014206896551724138, 'epoch': 0.63}\n",
      "{'loss': 1.1601, 'grad_norm': 0.27853938937187195, 'learning_rate': 0.0001406896551724138, 'epoch': 0.64}\n",
      "{'loss': 1.5204, 'grad_norm': 0.32627299427986145, 'learning_rate': 0.0001393103448275862, 'epoch': 0.65}\n",
      "{'loss': 1.6662, 'grad_norm': 0.3135022222995758, 'learning_rate': 0.00013793103448275863, 'epoch': 0.67}\n",
      "{'loss': 1.1994, 'grad_norm': 0.3219599425792694, 'learning_rate': 0.00013655172413793104, 'epoch': 0.68}\n",
      "{'loss': 0.97, 'grad_norm': 0.2975424826145172, 'learning_rate': 0.00013517241379310346, 'epoch': 0.69}\n",
      "{'loss': 0.9347, 'grad_norm': 0.31972041726112366, 'learning_rate': 0.00013379310344827588, 'epoch': 0.71}\n",
      "{'loss': 1.2954, 'grad_norm': 0.3308938145637512, 'learning_rate': 0.0001324137931034483, 'epoch': 0.72}\n",
      "{'loss': 1.1167, 'grad_norm': 0.30006834864616394, 'learning_rate': 0.00013103448275862068, 'epoch': 0.73}\n",
      "{'loss': 1.2456, 'grad_norm': 0.27112480998039246, 'learning_rate': 0.0001296551724137931, 'epoch': 0.75}\n",
      "{'loss': 1.2959, 'grad_norm': 0.2567978799343109, 'learning_rate': 0.00012827586206896552, 'epoch': 0.76}\n",
      "{'loss': 1.251, 'grad_norm': 0.2939544916152954, 'learning_rate': 0.00012689655172413793, 'epoch': 0.77}\n",
      "{'loss': 1.5062, 'grad_norm': 0.28949886560440063, 'learning_rate': 0.00012551724137931035, 'epoch': 0.79}\n",
      "{'loss': 1.5183, 'grad_norm': 0.24751828610897064, 'learning_rate': 0.00012413793103448277, 'epoch': 0.8}\n",
      "{'loss': 0.7903, 'grad_norm': 0.2807929515838623, 'learning_rate': 0.00012275862068965518, 'epoch': 0.81}\n",
      "{'loss': 1.4128, 'grad_norm': 0.28368398547172546, 'learning_rate': 0.00012137931034482759, 'epoch': 0.83}\n",
      "{'loss': 0.9828, 'grad_norm': 0.26558154821395874, 'learning_rate': 0.00012, 'epoch': 0.84}\n",
      "{'loss': 1.1729, 'grad_norm': 0.275177925825119, 'learning_rate': 0.0001186206896551724, 'epoch': 0.85}\n",
      "{'loss': 1.4113, 'grad_norm': 0.3224092423915863, 'learning_rate': 0.00011724137931034482, 'epoch': 0.87}\n",
      "{'loss': 1.286, 'grad_norm': 0.27626755833625793, 'learning_rate': 0.00011586206896551725, 'epoch': 0.88}\n",
      "{'loss': 1.0696, 'grad_norm': 0.229588583111763, 'learning_rate': 0.00011448275862068967, 'epoch': 0.89}\n",
      "{'loss': 1.7209, 'grad_norm': 0.2746301591396332, 'learning_rate': 0.00011310344827586207, 'epoch': 0.91}\n",
      "{'loss': 2.0787, 'grad_norm': 0.3383708596229553, 'learning_rate': 0.00011172413793103449, 'epoch': 0.92}\n",
      "{'loss': 1.6433, 'grad_norm': 0.2910342216491699, 'learning_rate': 0.0001103448275862069, 'epoch': 0.93}\n",
      "{'loss': 1.2911, 'grad_norm': 0.25566035509109497, 'learning_rate': 0.00010896551724137931, 'epoch': 0.95}\n",
      "{'loss': 1.5121, 'grad_norm': 0.3150213360786438, 'learning_rate': 0.00010758620689655173, 'epoch': 0.96}\n",
      "{'loss': 1.2324, 'grad_norm': 0.2914729416370392, 'learning_rate': 0.00010620689655172413, 'epoch': 0.97}\n",
      "{'loss': 1.0357, 'grad_norm': 0.28547587990760803, 'learning_rate': 0.00010482758620689656, 'epoch': 0.99}\n",
      "{'loss': 1.6798, 'grad_norm': 0.2874602675437927, 'learning_rate': 0.00010344827586206898, 'epoch': 1.0}\n",
      "{'loss': 1.1341, 'grad_norm': 0.23726296424865723, 'learning_rate': 0.0001020689655172414, 'epoch': 1.01}\n",
      "{'loss': 0.9381, 'grad_norm': 0.22969862818717957, 'learning_rate': 0.0001006896551724138, 'epoch': 1.03}\n",
      "{'loss': 1.1135, 'grad_norm': 0.2542813718318939, 'learning_rate': 9.931034482758621e-05, 'epoch': 1.04}\n",
      "{'loss': 0.8707, 'grad_norm': 0.2578168213367462, 'learning_rate': 9.793103448275862e-05, 'epoch': 1.05}\n",
      "{'loss': 0.9137, 'grad_norm': 0.24316908419132233, 'learning_rate': 9.655172413793105e-05, 'epoch': 1.07}\n",
      "{'loss': 0.9254, 'grad_norm': 0.26020777225494385, 'learning_rate': 9.517241379310345e-05, 'epoch': 1.08}\n",
      "{'loss': 1.1231, 'grad_norm': 0.31835609674453735, 'learning_rate': 9.379310344827587e-05, 'epoch': 1.09}\n",
      "{'loss': 1.0648, 'grad_norm': 0.3091212809085846, 'learning_rate': 9.241379310344827e-05, 'epoch': 1.11}\n",
      "{'loss': 1.1547, 'grad_norm': 0.28830480575561523, 'learning_rate': 9.10344827586207e-05, 'epoch': 1.12}\n",
      "{'loss': 1.2338, 'grad_norm': 0.33963972330093384, 'learning_rate': 8.96551724137931e-05, 'epoch': 1.13}\n",
      "{'loss': 1.0643, 'grad_norm': 0.4617918133735657, 'learning_rate': 8.827586206896552e-05, 'epoch': 1.15}\n",
      "{'loss': 1.0945, 'grad_norm': 0.29067516326904297, 'learning_rate': 8.689655172413794e-05, 'epoch': 1.16}\n",
      "{'loss': 1.47, 'grad_norm': 0.3275492787361145, 'learning_rate': 8.551724137931035e-05, 'epoch': 1.17}\n",
      "{'loss': 0.9634, 'grad_norm': 0.38390135765075684, 'learning_rate': 8.413793103448277e-05, 'epoch': 1.19}\n",
      "{'loss': 0.9976, 'grad_norm': 0.2822698950767517, 'learning_rate': 8.275862068965517e-05, 'epoch': 1.2}\n",
      "{'loss': 1.3411, 'grad_norm': 0.35668885707855225, 'learning_rate': 8.137931034482759e-05, 'epoch': 1.21}\n",
      "{'loss': 1.3649, 'grad_norm': 0.31190216541290283, 'learning_rate': 8e-05, 'epoch': 1.23}\n",
      "{'loss': 1.153, 'grad_norm': 0.29429006576538086, 'learning_rate': 7.862068965517242e-05, 'epoch': 1.24}\n",
      "{'loss': 1.1479, 'grad_norm': 0.321270227432251, 'learning_rate': 7.724137931034483e-05, 'epoch': 1.25}\n",
      "{'loss': 1.1037, 'grad_norm': 0.2707175612449646, 'learning_rate': 7.586206896551724e-05, 'epoch': 1.27}\n",
      "{'loss': 1.2471, 'grad_norm': 0.35123416781425476, 'learning_rate': 7.448275862068966e-05, 'epoch': 1.28}\n",
      "{'loss': 0.8932, 'grad_norm': 0.3840661942958832, 'learning_rate': 7.310344827586208e-05, 'epoch': 1.29}\n",
      "{'loss': 1.0706, 'grad_norm': 0.3492239713668823, 'learning_rate': 7.172413793103448e-05, 'epoch': 1.31}\n",
      "{'loss': 1.2133, 'grad_norm': 0.28896287083625793, 'learning_rate': 7.03448275862069e-05, 'epoch': 1.32}\n",
      "{'loss': 0.8619, 'grad_norm': 0.3629564940929413, 'learning_rate': 6.896551724137931e-05, 'epoch': 1.33}\n",
      "{'loss': 0.6801, 'grad_norm': 0.31824132800102234, 'learning_rate': 6.758620689655173e-05, 'epoch': 1.35}\n",
      "{'loss': 1.1601, 'grad_norm': 0.4140734076499939, 'learning_rate': 6.620689655172415e-05, 'epoch': 1.36}\n",
      "{'loss': 1.1185, 'grad_norm': 0.4035284221172333, 'learning_rate': 6.482758620689655e-05, 'epoch': 1.37}\n",
      "{'loss': 1.4269, 'grad_norm': 0.3150714337825775, 'learning_rate': 6.344827586206897e-05, 'epoch': 1.39}\n",
      "{'loss': 1.3691, 'grad_norm': 0.6292389631271362, 'learning_rate': 6.206896551724138e-05, 'epoch': 1.4}\n",
      "{'loss': 1.1022, 'grad_norm': 0.37910982966423035, 'learning_rate': 6.068965517241379e-05, 'epoch': 1.41}\n",
      "{'loss': 1.1566, 'grad_norm': 0.29645881056785583, 'learning_rate': 5.93103448275862e-05, 'epoch': 1.43}\n",
      "{'loss': 0.8813, 'grad_norm': 0.39861539006233215, 'learning_rate': 5.7931034482758627e-05, 'epoch': 1.44}\n",
      "{'loss': 0.9111, 'grad_norm': 0.34214457869529724, 'learning_rate': 5.6551724137931037e-05, 'epoch': 1.45}\n",
      "{'loss': 0.8875, 'grad_norm': 0.30416566133499146, 'learning_rate': 5.517241379310345e-05, 'epoch': 1.47}\n",
      "{'loss': 1.0693, 'grad_norm': 0.3893584907054901, 'learning_rate': 5.379310344827586e-05, 'epoch': 1.48}\n",
      "{'loss': 1.0884, 'grad_norm': 0.40492454171180725, 'learning_rate': 5.241379310344828e-05, 'epoch': 1.49}\n",
      "{'loss': 1.3314, 'grad_norm': 0.33690446615219116, 'learning_rate': 5.10344827586207e-05, 'epoch': 1.51}\n",
      "{'loss': 1.2987, 'grad_norm': 0.3248027563095093, 'learning_rate': 4.9655172413793107e-05, 'epoch': 1.52}\n",
      "{'loss': 0.9162, 'grad_norm': 0.3474727272987366, 'learning_rate': 4.827586206896552e-05, 'epoch': 1.53}\n",
      "{'loss': 1.0057, 'grad_norm': 0.31149622797966003, 'learning_rate': 4.689655172413793e-05, 'epoch': 1.55}\n",
      "{'loss': 1.1193, 'grad_norm': 0.3803168535232544, 'learning_rate': 4.551724137931035e-05, 'epoch': 1.56}\n",
      "{'loss': 1.0859, 'grad_norm': 0.37280896306037903, 'learning_rate': 4.413793103448276e-05, 'epoch': 1.57}\n",
      "{'loss': 1.0378, 'grad_norm': 0.3225773870944977, 'learning_rate': 4.275862068965518e-05, 'epoch': 1.59}\n",
      "{'loss': 0.9689, 'grad_norm': 0.4199758470058441, 'learning_rate': 4.1379310344827587e-05, 'epoch': 1.6}\n",
      "{'loss': 1.2235, 'grad_norm': 0.2779756784439087, 'learning_rate': 4e-05, 'epoch': 1.61}\n",
      "{'loss': 1.01, 'grad_norm': 0.45688846707344055, 'learning_rate': 3.862068965517241e-05, 'epoch': 1.63}\n",
      "{'loss': 1.1242, 'grad_norm': 0.4194619655609131, 'learning_rate': 3.724137931034483e-05, 'epoch': 1.64}\n",
      "{'loss': 1.1394, 'grad_norm': 0.27757638692855835, 'learning_rate': 3.586206896551724e-05, 'epoch': 1.65}\n",
      "{'loss': 1.0554, 'grad_norm': 0.3188657760620117, 'learning_rate': 3.4482758620689657e-05, 'epoch': 1.67}\n",
      "{'loss': 0.8457, 'grad_norm': 0.3422756791114807, 'learning_rate': 3.310344827586207e-05, 'epoch': 1.68}\n",
      "{'loss': 1.2039, 'grad_norm': 0.3869639039039612, 'learning_rate': 3.172413793103448e-05, 'epoch': 1.69}\n",
      "{'loss': 1.2102, 'grad_norm': 0.6667678952217102, 'learning_rate': 3.0344827586206897e-05, 'epoch': 1.71}\n",
      "{'loss': 1.4096, 'grad_norm': 0.3977920711040497, 'learning_rate': 2.8965517241379313e-05, 'epoch': 1.72}\n",
      "{'loss': 1.1053, 'grad_norm': 0.36530226469039917, 'learning_rate': 2.7586206896551727e-05, 'epoch': 1.73}\n",
      "{'loss': 0.8788, 'grad_norm': 0.3942785859107971, 'learning_rate': 2.620689655172414e-05, 'epoch': 1.75}\n",
      "{'loss': 1.0169, 'grad_norm': 0.31347477436065674, 'learning_rate': 2.4827586206896553e-05, 'epoch': 1.76}\n",
      "{'loss': 1.5546, 'grad_norm': 0.41141077876091003, 'learning_rate': 2.3448275862068967e-05, 'epoch': 1.77}\n",
      "{'loss': 1.1674, 'grad_norm': 0.4695243835449219, 'learning_rate': 2.206896551724138e-05, 'epoch': 1.79}\n",
      "{'loss': 1.096, 'grad_norm': 0.36555007100105286, 'learning_rate': 2.0689655172413793e-05, 'epoch': 1.8}\n",
      "{'loss': 0.9871, 'grad_norm': 0.32644951343536377, 'learning_rate': 1.9310344827586207e-05, 'epoch': 1.81}\n",
      "{'loss': 0.818, 'grad_norm': 0.2593478560447693, 'learning_rate': 1.793103448275862e-05, 'epoch': 1.83}\n",
      "{'loss': 1.0286, 'grad_norm': 0.4608525335788727, 'learning_rate': 1.6551724137931037e-05, 'epoch': 1.84}\n",
      "{'loss': 0.8022, 'grad_norm': 0.3864782154560089, 'learning_rate': 1.5172413793103448e-05, 'epoch': 1.85}\n",
      "{'loss': 0.847, 'grad_norm': 0.358096718788147, 'learning_rate': 1.3793103448275863e-05, 'epoch': 1.87}\n",
      "{'loss': 1.1064, 'grad_norm': 0.32414138317108154, 'learning_rate': 1.2413793103448277e-05, 'epoch': 1.88}\n",
      "{'loss': 1.237, 'grad_norm': 0.3504667580127716, 'learning_rate': 1.103448275862069e-05, 'epoch': 1.89}\n",
      "{'loss': 0.9978, 'grad_norm': 0.4184599816799164, 'learning_rate': 9.655172413793103e-06, 'epoch': 1.91}\n",
      "{'loss': 0.9318, 'grad_norm': 0.4286760091781616, 'learning_rate': 8.275862068965518e-06, 'epoch': 1.92}\n",
      "{'loss': 1.1996, 'grad_norm': 0.3829709589481354, 'learning_rate': 6.896551724137932e-06, 'epoch': 1.93}\n",
      "{'loss': 1.1939, 'grad_norm': 0.4092148542404175, 'learning_rate': 5.517241379310345e-06, 'epoch': 1.95}\n",
      "{'loss': 0.9711, 'grad_norm': 0.400917112827301, 'learning_rate': 4.137931034482759e-06, 'epoch': 1.96}\n",
      "{'loss': 0.9776, 'grad_norm': 0.41282913088798523, 'learning_rate': 2.7586206896551725e-06, 'epoch': 1.97}\n",
      "{'loss': 1.6381, 'grad_norm': 0.44217678904533386, 'learning_rate': 1.3793103448275862e-06, 'epoch': 1.99}\n",
      "{'loss': 1.1987, 'grad_norm': 0.3785339891910553, 'learning_rate': 0.0, 'epoch': 2.0}\n",
      "{'train_runtime': 203.7757, 'train_samples_per_second': 5.889, 'train_steps_per_second': 0.736, 'train_loss': 1.187286684513092, 'epoch': 2.0}\n"
     ]
    }
   ],
   "source": [
    "trainer_stats = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system\n",
      "You are a helpful assistant.<|im_end|>\n",
      "<|im_start|>user\n",
      "Can you tell me about triangles...<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Certainly! A triangle is a fundamental geometric shape consisting of three straight sides and three angles. The sum of the interior angles in any triangle always adds up to 180 degrees, which is a key property that distinguishes it from other polygon shapes.\n",
      "\n",
      "Triangles can be classified based on their side lengths or angle measurements:\n",
      "\n",
      "**By Side Lengths:**\n",
      "- **Equilateral Triangle:** All three sides are equal in length.\n",
      "- **Isosceles Triangle:** Two sides are equal in length.\n",
      "- **Scalene Triangle:** No sides are equal in length.\n",
      "\n",
      "**By Angles:**\n",
      "- **Acute Triangle:** All three internal angles are less than 90 degrees (acute).\n",
      "- **Right Triangle:** One internal angle is exactly 90 degrees (right angle), and the other two are acute.\n",
      "- **Obtuse Triangle:** One internal angle is greater than 90 degrees (obtuse) and the other two are acute.\n",
      "\n",
      "Triangles have many interesting properties and applications in mathematics, science, engineering, and everyday life. They are used in architecture for structural support, in art for creating aesthetically pleasing designs, and in computer graphics for various transformations and animations. Additionally, triangles form the building blocks for more complex geometric shapes like quadrilaterals, pentagons, hexagons, and beyond.<|im_end|>\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"<|im_start|>system\n",
    "You are a helpful assistant.<|im_end|>\n",
    "<|im_start|>user\n",
    "Can you tell me about triangles...<|im_end|>\n",
    "<|im_start|>assistant\n",
    "\"\"\"\n",
    "\n",
    "FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
    "inputs=tokenizer([prompt], return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "outputs=model.generate(**inputs, max_new_tokens=1024, use_cache=True)\n",
    "print(tokenizer.batch_decode(outputs)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: You're not saving a tokenizer as well?\n",
      "You can do it separately via `tokenizer.save_pretrained(...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Merging 4bit and LoRA weights to 16bit...\n",
      "Unsloth: Will use up to 11.47 out of 31.11 RAM for saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [00:00<00:00, 183.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unsloth: Saving model... This might take 5 minutes for Llama-7b...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "model.save_pretrained_merged(\"output\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
